

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>6. Joint Probability (Discrete) &#8212; Probabilistic Foundations of Machine Learning (CS349)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'materials/probability-joint';</script>
    <link rel="canonical" href="https://mogu-lab.github.io/cs349-fall-2024/materials/probability-joint.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. The Basics of Frequentist Learning" href="frequentist-learning.html" />
    <link rel="prev" title="5. Conditional Probability (Discrete)" href="probability-conditional.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Probabilistic Foundations of ML
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. What is Probabilistic ML?</a></li>
<li class="toctree-l1"><a class="reference internal" href="vectorization-basics.html">2. An Introduction to “Vectorization” in <code class="docutils literal notranslate"><span class="pre">Jax</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="vectorization-advanced.html">3. Advanced Vectorization in <code class="docutils literal notranslate"><span class="pre">Jax</span></code></a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Model Specification</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="probability-discrete.html">4. Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-conditional.html">5. Conditional Probability (Discrete)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">6. Joint Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="frequentist-learning.html">7. The Basics of Frequentist Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-continuous.html">8. Continuous Probability</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Predictive Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="regression.html">9. Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Generative Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="latent-variable-models.html">10. Latent Variable Models (LVMs)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="inference.html">11. Inference</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/mogu-lab/cs349-fall-2024/blob/master/materials/probability-joint.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li><a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fmogu-lab%2Fcs349-fall-2024%2Fblob%2Fmaster%2Fmaterials/probability-joint.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onDeepnote"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_deepnote.svg">
  </span>
<span class="btn__text-container">Deepnote</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/materials/probability-joint.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Joint Probability (Discrete)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology-and-notation">6.1. Terminology and Notation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#translating-math-to-code-with-numpyro">6.2. Translating Math to Code with <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="joint-probability-discrete">
<h1><span class="section-number">6. </span>Joint Probability (Discrete)<a class="headerlink" href="#joint-probability-discrete" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import some helper functions (please ignore this!)</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span> 
</pre></div>
</div>
</div>
</div>
<p><strong>Context:</strong> So far, you’ve spent some time conducting a preliminary exploratory data analysis (EDA) of IHH’s ER data. You noticed that considering variables separately can result in misleading information. As a result, you decided to use <em>conditional distributions</em> to model the <em>relationship between variables</em>. Using these conditional distributions, you were able to develop <em>predictive models</em> (e.g. predicting the probability of intoxication given the day of the week), These predictive models are useful for the IHH administration to make decisions.</p>
<p>However, you’ve noticed that your modeling toolkit is still limited. The conditional distributions we introduced can model how the probability of one variable changes given a <em>set</em> of variables. What if we wanted to describe how the probability of a <em>set</em> of variables (i.e. more than one) changes given a <em>set</em> of variables? For example, we may want to answer questions like: “how does the probability that a patient is hospitalized for an allergic reaction change given the day of the week?” In this question, we’re inquiring about two variables—that the condition is an allergic reaction, <em>and</em> that the patient was hospitalized—given the day of the week.</p>
<p><strong>Challenge:</strong> We need to expand our modeling toolkit to include yet another tool—joint probabilities.</p>
<p><strong>Outline:</strong></p>
<ol class="arabic simple">
<li><p>Introduce and practice the concepts, terminology, and notation behind discrete joint probability distributions (leaving continuous distributions to a later time).</p></li>
<li><p>Introduce a graphical representation to describe joint distributions.</p></li>
<li><p>Translate this graphical representation directly into code in a probabilistic programming language (using <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>) that we can then use to fit the data.</p></li>
</ol>
<section id="terminology-and-notation">
<h2><span class="section-number">6.1. </span>Terminology and Notation<a class="headerlink" href="#terminology-and-notation" title="Permalink to this heading">#</a></h2>
<p>We, again introduce the statistical language—terminology and notation—to precisely specify to a computer how to model our data. We will then translate statements in this language directly into code in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> that a computer can run.</p>
<p><strong>Concept:</strong> The concept behind a joint probability is elegant; it allows us to build complicated distributions over many variables using simple conditional and non-conditional distributions (that we already covered).</p>
<p>We can illustrate this using an example with just two variables. Suppose you have two RVs, <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>. The probability that <span class="math notranslate nohighlight">\(A = a\)</span> and <span class="math notranslate nohighlight">\(B = b\)</span> are <em>both</em> satisfied is called their <em>joint probability</em>. It is denoted by <span class="math notranslate nohighlight">\(p_{A,B}(a, b)\)</span>. This joint distribution can be <em>factorized</em> to a product of conditional and non-conditional (or “marginal”) distributions as follows:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
p_{A, B}(a, b) &amp;= p_{A | B}(a | b) \cdot p_B(b) \quad \text{(Option 1)} \\
\underbrace{\phantom{p_{A, B}(a, b)}}_{\text{joint}} &amp;= \underbrace{p_{B | A}(b | a)}_{\text{conditional}} \cdot \underbrace{p_A(a)}_{\text{marginal}} \quad \text{(Option 2)}
\end{align*}\]</div>
<p>Notice that the joint is now described in terms of conditional and marginal distributions, which we already know how to work with!</p>
<p><strong>Intuition:</strong> So what’s the intuition behind this formula? Let’s depict events <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> as follows:</p>
<a class="reference internal image-reference" href="../_images/joint-probability-venn.png"><img alt="../_images/joint-probability-venn.png" class="align-center" src="../_images/joint-probability-venn.png" style="width: 500px;" /></a>
<p>Using the above diagram, we can pictorally represent all distributions of interest. The marginal <span class="math notranslate nohighlight">\(p_B(b)\)</span> is the ratio of the blue circle relative to the whole space (the gray square):</p>
<a class="reference internal image-reference" href="../_images/joint-probability-eq-marginal.png"><img alt="../_images/joint-probability-eq-marginal.png" class="align-center" src="../_images/joint-probability-eq-marginal.png" style="width: 300px;" /></a>
<p>The conditional <span class="math notranslate nohighlight">\(p_{A | B}(a | b)\)</span> is the ratio of the purple intersection relative to the blue circle. This is because the blue circle represents us conditioning on <span class="math notranslate nohighlight">\(B = b\)</span>, and the intersection of the circles represents the observations for which we <em>also</em> have <span class="math notranslate nohighlight">\(A = a\)</span>.</p>
<a class="reference internal image-reference" href="../_images/joint-probability-eq-conditional.png"><img alt="../_images/joint-probability-eq-conditional.png" class="align-center" src="../_images/joint-probability-eq-conditional.png" style="width: 300px;" /></a>
<p>Finally, the joint <span class="math notranslate nohighlight">\(p_{A, B}(a, b)\)</span> is the ratio between the purple intersection and the whole space (the gray square). This is because the intersection is the place where both <span class="math notranslate nohighlight">\(A = a\)</span> and <span class="math notranslate nohighlight">\(B = b\)</span>.</p>
<a class="reference internal image-reference" href="../_images/joint-probability-eq-joint.png"><img alt="../_images/joint-probability-eq-joint.png" class="align-center" src="../_images/joint-probability-eq-joint.png" style="width: 300px;" /></a>
<p>Now we can see that the joint is the product of the conditional and the marginal because the blue circles “cancel out”:</p>
<a class="reference internal image-reference" href="../_images/joint-probability-eq-joint-expanded.png"><img alt="../_images/joint-probability-eq-joint-expanded.png" class="align-center" src="../_images/joint-probability-eq-joint-expanded.png" style="width: 500px;" /></a>
<p><strong>Choice of Factorization:</strong> Lastly, notice that we have a <em>choice</em> to factorize the distribution in two ways. How do you know which one to use? Typically, we choose a factorization that is <em>intuitive to us</em> and what we can compute.</p>
<blockquote>
<div><p>For example, suppose you want to model the joint distribution of the day of the week, <span class="math notranslate nohighlight">\(D\)</span> and whether a patient arrive with intoxication, <span class="math notranslate nohighlight">\(I\)</span>. The joint distribution can be factorized in two ways:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
p_{D, I}(d, i) &amp;= p_{I | D}(i | d) \cdot p_D(d) \quad \text{(Option 1)} \\
&amp;= p_{D | I}(d | i) \cdot p_I(i) \quad \text{(Option 2)} \\
\end{align*}\]</div>
<p>Which one makes more intuitive sense? Well, it’s a little weird to try to predict the day of the week given whether a patient arrives with intoxication; we typically know what the day of the week is and we don’t need to predict it. In contrast, given the day of the week, it makes a lot of sense to wonder about the probability of a patient arriving with intoxication. As such, Option 1 makes more sense here.</p>
</div></blockquote>
<p><strong>Generalizing to More than Two RVs:</strong> So now we have the tools to work with joint distributions with two RVs. What do we do if we have three or more? The same ideas apply. The joint distribution for random variables <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span>, and <span class="math notranslate nohighlight">\(C\)</span> can be factorized in a number of ways. For example, we can condition on two variables at a time:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
p_{A, B, C}(a, b, c) &amp;= p_{A | B, C}(a | b, c) \cdot p_{B, C}(b, c) \quad \text{(Option 1)} \\
&amp;= p_{B | A, C}(b | a, c) \cdot p_{A, C}(a, c) \quad \text{(Option 2)} \\
&amp;= p_{C | A, B}(c | a, b) \cdot p_{A, B}(a, b) \quad \text{(Option 3)}
\end{align*}\]</div>
<p>Here, we already know how to factorize <span class="math notranslate nohighlight">\(p_{B, C}(b, c)\)</span>, <span class="math notranslate nohighlight">\(p_{A, C}(a, c)\)</span>, and <span class="math notranslate nohighlight">\(p_{A, B}(a, b)\)</span>.</p>
<p>We can also condition on one variable at a time:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
p_{A, B, C}(a, b, c) &amp;= p_{A, B | C}(a, b | c) \cdot p_C(c) \quad \text{(Option 1)} \\
&amp;= p_{A, C | B}(a, c | b) \cdot p_B(b) \quad \text{(Option 2)} \\
&amp;= p_{B, C | A}(b, c | a) \cdot p_A(a) \quad \text{(Option 3)}
\end{align*}\]</div>
<p>And how do we further factorize distributions of the form <span class="math notranslate nohighlight">\(p_{A, B | C}(a, b | c)\)</span>? We apply the same factorization for a joint distribution with two variables, and simply add a “conditioned on <span class="math notranslate nohighlight">\(C\)</span>” to each one:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
p_{A, B | C}(a, b | c) &amp;= p_{A | B, C}(a | b, c) \cdot p_{B | C}(b | c) \quad \text{(Option 1)} \\
&amp;= p_{B | A, C}(b | a, c) \cdot p_{A | C}(a | c) \quad \text{(Option 2)} \\
\end{align*}\]</div>
</section>
<section id="translating-math-to-code-with-numpyro">
<h2><span class="section-number">6.2. </span>Translating Math to Code with <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code><a class="headerlink" href="#translating-math-to-code-with-numpyro" title="Permalink to this heading">#</a></h2>
<p><strong>What is <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>?</strong> <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> is a “Probabilistic Programming Language” based in <code class="docutils literal notranslate"><span class="pre">Jax</span></code>. It provides an interface for (nearly) direct translation of the stats/math we wrote above into code that we can use to fit to data, make predictions, and more. This will allow us to focus on the conceptual ideas behind probabilistic ML.</p>
<p><strong>Instantiating Distributions in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>.</strong> <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> comes with many distributions already implemented. For a complete list of all available discrete distributions, check out the <a class="reference external" href="https://num.pyro.ai/en/stable/distributions.html#discrete-distributions">this part of the documentation</a>. So why use <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> instead of implementing the distributions on our own? It’s easy to write subtle bugs that are hard to catch when implementing mathematical formulas in code. Also, using <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>’s distributions will help us highlight the overall <em>logic</em> of the code, instead of getting bogged down by the mathematical details.</p>
<p>Distributions in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> have several notable properties and methods we will rely on. Let’s explore them together. First, we import the necessary components of <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">jax.random</span> <span class="k">as</span> <span class="nn">jrandom</span>
<span class="kn">import</span> <span class="nn">numpyro</span>
<span class="kn">import</span> <span class="nn">numpyro.distributions</span> <span class="k">as</span> <span class="nn">D</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s instantiate the simplest discrete distribution we know: the Bernoulli distribution.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
p_X(x) &amp;= \mathrm{Bern}(\rho) = \rho^x \cdot (1 - \rho)^{1 - x}
\end{align*}\]</div>
<p>Recall that a Bernoulli distribution takes in just one parameter, <span class="math notranslate nohighlight">\(\rho \in [0, 1]\)</span>, which determines the probability of sampling <span class="math notranslate nohighlight">\(X = 1\)</span> vs. <span class="math notranslate nohighlight">\(X = 0\)</span>. Here let’s instantiate the Bernoulli distribution with <span class="math notranslate nohighlight">\(\rho = 0.7\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rho</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">p_X</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">rho</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>That’s it!</p>
<p><strong>Evaluating the PMF of <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> Distributions.</strong> Now, if we want to evaluate the PMF, we can use <code class="docutils literal notranslate"><span class="pre">log_prob</span></code> method as follows (note that this returns the <em>log</em> of the PMF, so we’ll have to exponentiate the result):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_p_x_eq_1</span> <span class="o">=</span> <span class="n">p_X</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Probability of sampling a 1:&#39;</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p_x_eq_1</span><span class="p">))</span>

<span class="n">log_p_x_eq_0</span> <span class="o">=</span> <span class="n">p_X</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Probability of sampling a 0:&#39;</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p_x_eq_0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Probability of sampling a 1: 0.7
Probability of sampling a 0: 0.3
</pre></div>
</div>
</div>
</div>
<p><strong>Sampling from <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> Distributions.</strong> <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> distributions all have a <code class="docutils literal notranslate"><span class="pre">sample</span></code> method which can be used to draw samples. It takes in two arguments:</p>
<ol class="arabic simple">
<li><p>A random-generator “key,” which controls the randomness of the sample.</p></li>
<li><p>A shape, describing the number of i.i.d samples you want to draw.</p></li>
</ol>
<p>Let’s give it a go:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,)</span> <span class="c1"># Shape of i.i.d samples we wish to draw </span>

<span class="n">key1</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Create a random-generator key</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;First batch drawn with key1: &#39;</span><span class="p">,</span> <span class="n">p_X</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key1</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Second batch drawn with key1:&#39;</span><span class="p">,</span> <span class="n">p_X</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key1</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>

<span class="n">key2</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Create a random-generator key</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Third batch drawn with key2: &#39;</span><span class="p">,</span> <span class="n">p_X</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key2</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First batch drawn with key1:  [1 0 1 0 1 1 0 1 1 1 0 0 1 1 1]
Second batch drawn with key1: [1 0 1 0 1 1 0 1 1 1 0 0 1 1 1]
Third batch drawn with key2:  [1 1 1 0 1 1 1 1 1 1 1 1 0 1 1]
</pre></div>
</div>
</div>
</div>
<p>Notice in the above code, when using the same key twice (or the same <code class="docutils literal notranslate"><span class="pre">seed</span></code>), we get the <em>exact same batch of samples</em>. This is both a blessing and a curse. It’s a blessing because this allows us to precisely control the randomness of our ML code. This will prove crucial for debugging later on. However, it can also be a curse if we accidentally use the same key in a place where we need two different sources of randomness.</p>
<p><strong>Best Practice: How to Manage Your Keys.</strong> As a rule of thumb, we introduce the following paradigm: NEVER USE THE SAME KEY TWICE. How can we do this? <code class="docutils literal notranslate"><span class="pre">Jax</span></code> allows us to take a random key and split it into multiple different keys, each of which can be used for different purposes. This means we can create ONE KEY to control the randomness of our entire code. We can then split this key into multiple keys as needed. Here’s how we can do this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create ONE KEY to be used by your ENTIRE CODE</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Whenever you need to use the key for multiple purposes, split it into parts:</span>
<span class="n">key_first</span><span class="p">,</span> <span class="n">key_second</span><span class="p">,</span> <span class="n">key_third</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> 

<span class="c1"># Use each part for each need</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;First batch drawn with key_first:  &#39;</span><span class="p">,</span> <span class="n">p_X</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key_first</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Second batch drawn with key_second:&#39;</span><span class="p">,</span> <span class="n">p_X</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key_second</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Second batch drawn with key_third: &#39;</span><span class="p">,</span> <span class="n">p_X</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key_third</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First batch drawn with key_first:   [1 1 1 1 1 1 1 1 0 1 1 0 1 1 1]
Second batch drawn with key_second: [1 1 0 0 1 1 0 1 1 1 0 1 1 0 1]
Second batch drawn with key_third:  [0 0 1 1 1 1 1 1 1 0 1 1 1 0 0]
</pre></div>
</div>
</div>
</div>
<p><strong>Vectorizing <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> Distributions.</strong></p>
<p><strong>Sampling from Joint Distributions:</strong></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
d &amp;\sim p_D(\cdot) \\
c | d &amp;\sim p_{C | D}(\cdot | d) \\
h | c &amp;\sim p_{H | C}(\cdot | c) \\
m | c &amp;\sim p_{M | C}(\cdot | c) \\
a | c, h &amp;\sim p_{A | C, H}(\cdot | c, h)
\end{align*}\]</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./materials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="probability-conditional.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Conditional Probability (Discrete)</p>
      </div>
    </a>
    <a class="right-next"
       href="frequentist-learning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7. </span>The Basics of Frequentist Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology-and-notation">6.1. Terminology and Notation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#translating-math-to-code-with-numpyro">6.2. Translating Math to Code with <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yaniv Yacoby
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>