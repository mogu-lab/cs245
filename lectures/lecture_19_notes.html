

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>38. Lecture #19: Variational Inference in Context &#8212; Probabilistic Foundations of Machine Learning (CS349)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/lecture_19_notes';</script>
    <link rel="canonical" href="https://mogu-lab.github.io/cs349-fall-2024/lectures/lecture_19_notes.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="43. Lecture #20: Variational Autoencoders" href="lecture_20_notes.html" />
    <link rel="prev" title="35. Lecture #18: Automatic Differentiation" href="lecture_18_notes.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Probabilistic Foundations of Machine Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Exact Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture_1_notes.html">1. Lecture #1: Course Overview</a></li>





<li class="toctree-l1"><a class="reference internal" href="lecture_2_notes.html">7. Lecture #2: Maximimum Likelihood Estimation</a></li>






<li class="toctree-l1"><a class="reference internal" href="lecture_3_notes.html">14. Lecture #3: Bayesian Modeling</a></li>






<li class="toctree-l1"><a class="reference internal" href="lecture_4_notes.html">21. Lecture #4: Bayesian versus Frequentist Inference</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Sampling-Based Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture_5_notes.html">1. Lecture #5: Sampling for Posterior Simulation</a></li>





<li class="toctree-l1"><a class="reference internal" href="lecture_6_notes.html">7. Lecture #6: Monte Carlo Integration</a></li>






<li class="toctree-l1"><a class="reference internal" href="lecture_7_notes.html">14. Lecture #7: Markov Chain Monte Carlo</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_8_notes.html">18. Lecture #8: Metropolis-Hastings and Gibbs</a></li>




<li class="toctree-l1"><a class="reference internal" href="lecture_9_notes.html">23. Lecture #9: Latent Variable Models and MLE</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Gradient-Based Inference</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture_10_notes.html">1. Lecture #10: Bayesian Latent Variable Models and Variational Inference</a></li>

<li class="toctree-l1"><a class="reference internal" href="lecture_11_notes.html">3. Lecture #11: Hierarchical Models</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_12_notes.html">7. Lecture #12: Logistic Regression and Gradient Descent</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_13_notes.html">11. Lecture #13: Stochastic Gradient Descent and Simulated Annealing</a></li>





<li class="toctree-l1"><a class="reference internal" href="lecture_14_notes.html">17. Lecture #14: Hamiltonian Monte Carlo</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_15_notes.html">21. Lecture #15: Parallel Tempering and Stochastic HMC</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_16_notes.html">25. Lecture #16: Neural Network Models for Regression</a></li>





<li class="toctree-l1"><a class="reference internal" href="lecture_17_notes.html">31. Lecture #17: Black-box Variational Inference</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_18_notes.html">35. Lecture #18: Automatic Differentiation</a></li>


<li class="toctree-l1 current active"><a class="current reference internal" href="#">38. Lecture #19: Variational Inference in Context</a></li>




<li class="toctree-l1"><a class="reference internal" href="lecture_20_notes.html">43. Lecture #20: Variational Autoencoders</a></li>


<li class="toctree-l1"><a class="reference internal" href="lecture_21_notes.html">46. Lecture #21: Implementation of Variational Autoencoders</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/mogu-lab/cs349-fall-2024/blob/master/lectures/lecture_19_notes.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li><a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fmogu-lab%2Fcs349-fall-2024%2Fblob%2Fmaster%2Flectures/lecture_19_notes.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onDeepnote"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_deepnote.svg">
  </span>
<span class="btn__text-container">Deepnote</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lectures/lecture_19_notes.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture #19: Variational Inference in Context</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">38. Lecture #19: Variational Inference in Context</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#outline">Outline</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-evaluate-approximate-inference">39. How to Evaluate Approximate Inference</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-good-is-your-variational-approximation-of-the-true-posterior">How Good is Your Variational Approximation of the True Posterior?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alternative-posterior-evaluation-metrics">Alternative Posterior Evaluation Metrics</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-improve-approximate-inference">40. How to Improve Approximate Inference</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#your-variational-approximation-sucks-can-you-fix-it">Your Variational Approximation Sucks, Can You Fix It?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#are-there-any-good-properties-of-variational-approximations-that-we-are-sure-about">Are There Any Good Properties of Variational Approximations that We Are Sure About?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-is-inference-for-neural-networks-hard">Why is Inference for Neural Networks Hard?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#it-s-weirder-than-you-can-imagine">It’s Weirder Than You Can Imagine</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#but-why-do-i-care">41. But why do I care?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-of-variational-approximation-for-real-down-stream-tasks">Evaluation of Variational Approximation for Real Down-stream Tasks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictiveness-of-the-variational-approximate-posterior">Predictiveness of the Variational Approximate Posterior</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quality-of-variational-approximate-posterior-predictive-uncertainty">Quality of Variational Approximate Posterior Predictive Uncertainty</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#does-a-poor-posterior-approximation-imply-a-poor-posterior-predictive">Does a Poor Posterior Approximation Imply a Poor Posterior Predictive?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#new-developments-in-deep-bayes">42. New Developments in Deep Bayes</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-s-wrong-with-posterior-approximations-for-bnns">What’s Wrong with Posterior Approximations for BNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-did-we-learn">What Did We Learn?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-s-wrong-with-the-predictions-from-mean-field-variational-posteriors-of-bnns">What’s Wrong with the Predictions from Mean-Field Variational Posteriors of BNNs?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relationships-between-deep-ensembles-and-bayesian-neural-networks">Relationships Between Deep Ensembles and Bayesian Neural Networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alternative-models-for-uncertainty-quantification">Alternative Models for Uncertainty Quantification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictive-uncertainties-of-alternative-deep-bayesian-models-may-not-be-better">Predictive Uncertainties of Alternative Deep Bayesian Models May Not be Better</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-uncertainties-do-we-need-in-deep-learning">What Uncertainties Do We Need in Deep Learning?</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-19-variational-inference-in-context">
<h1><span class="section-number">38. </span>Lecture #19: Variational Inference in Context<a class="headerlink" href="#lecture-19-variational-inference-in-context" title="Permalink to this heading">#</a></h1>
<section id="am-207-advanced-scientific-computing">
<h2>AM 207: Advanced Scientific Computing<a class="headerlink" href="#am-207-advanced-scientific-computing" title="Permalink to this heading">#</a></h2>
<section id="stochastic-methods-for-data-analysis-inference-and-optimization">
<h3>Stochastic Methods for Data Analysis, Inference and Optimization<a class="headerlink" href="#stochastic-methods-for-data-analysis-inference-and-optimization" title="Permalink to this heading">#</a></h3>
</section>
<section id="fall-2021">
<h3>Fall, 2021<a class="headerlink" href="#fall-2021" title="Permalink to this heading">#</a></h3>
<img src="fig/logos.jpg" style="height:150px;"><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### Import basic libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">autograd.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">autograd.numpy.random</span> <span class="k">as</span> <span class="nn">npr</span>
<span class="kn">import</span> <span class="nn">autograd.scipy.stats.multivariate_normal</span> <span class="k">as</span> <span class="nn">mvn</span>
<span class="kn">import</span> <span class="nn">autograd.scipy.stats.norm</span> <span class="k">as</span> <span class="nn">norm</span>
<span class="kn">from</span> <span class="nn">autograd</span> <span class="kn">import</span> <span class="n">grad</span>
<span class="kn">from</span> <span class="nn">autograd.misc.optimizers</span> <span class="kn">import</span> <span class="n">adam</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span> <span class="k">as</span> <span class="nn">sk</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="k">as</span> <span class="nn">animation</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">rc</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">3</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1">### Import basic libraries</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">numpy</span>
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">autograd.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">import</span> <span class="nn">autograd.numpy.random</span> <span class="k">as</span> <span class="nn">npr</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">import</span> <span class="nn">autograd.scipy.stats.multivariate_normal</span> <span class="k">as</span> <span class="nn">mvn</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;autograd&#39;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="outline">
<h2>Outline<a class="headerlink" href="#outline" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>How to Evaluate Approximate Inference</p></li>
<li><p>How to Improve Approximate Inference</p></li>
<li><p>Why do I care?</p></li>
</ol>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="how-to-evaluate-approximate-inference">
<h1><span class="section-number">39. </span>How to Evaluate Approximate Inference<a class="headerlink" href="#how-to-evaluate-approximate-inference" title="Permalink to this heading">#</a></h1>
<section id="how-good-is-your-variational-approximation-of-the-true-posterior">
<h2>How Good is Your Variational Approximation of the True Posterior?<a class="headerlink" href="#how-good-is-your-variational-approximation-of-the-true-posterior" title="Permalink to this heading">#</a></h2>
<p><strong>Question:</strong> Why is it hard to check that the variational posterior is a good approximation of the true posterior?</p>
<p>You can’t simply visualize the true posterior, since it’s 1) high dimensional, 2) intractable to sample form.</p>
<p><strong>Question:</strong> What if we computed the KL-divergence between the true posterior and the varaitional approximation?</p>
<p><a class="reference external" href="https://arxiv.org/abs/1910.04102">“Practical Posterior Error Bounds from Variational Objectives”</a>: Unfortunately, even when the KL-divergence between <span class="math notranslate nohighlight">\(q\)</span> and <span class="math notranslate nohighlight">\(p\)</span> is effectively zero, the difference between the means and variances of <span class="math notranslate nohighlight">\(q\)</span> and <span class="math notranslate nohighlight">\(p\)</span> can be <strong>arbitrarily large</strong>. That is, a small KL-divergence doesn’t capture our intuition about what it means for two distributions to be similar.</p>
</section>
<section id="alternative-posterior-evaluation-metrics">
<h2>Alternative Posterior Evaluation Metrics<a class="headerlink" href="#alternative-posterior-evaluation-metrics" title="Permalink to this heading">#</a></h2>
<p>In <a class="reference external" href="https://arxiv.org/abs/1802.02538">“Yes, But Did It Work: Evaluating Variational Inference”</a>, the authors proposes two alternative posterior evaluation metrics:</p>
<p><strong>1. The Pareto Smoothed Importance Sampling Diagnostic</strong>: If the variational approximation <span class="math notranslate nohighlight">\(q\)</span> is very different than <span class="math notranslate nohighlight">\(p\)</span>, then the importance sampling MC estimate of <span class="math notranslate nohighlight">\(\mathbb{E}_{p(\theta|\text{Data})}\left[ f(\theta) \right]\)</span>,
$<span class="math notranslate nohighlight">\(
\mathbb{E}_{p(\theta|\text{Data})}\left[ f(\theta) \right] \approx \frac{1}{S}\sum_{s=1}^S \frac{p(\theta|\text{Data})}{q(\theta)} f(\theta_s),\; \theta_s \sim q(\theta)
\)</span><span class="math notranslate nohighlight">\(
will have very high variance, due to the fact that the importance weights \)</span>\frac{p(\theta|\text{Data})}{q(\theta)}<span class="math notranslate nohighlight">\( will be very heterogeneous. Thus, methods of smoothing the weights, like ***Pareto Smoothed Importance Sampling (PSIS)*** will have poor performance. The efficacy of PSIS can be used as a diagnostic tool for testing if \)</span>q<span class="math notranslate nohighlight">\( is similar to \)</span>p$.</p>
<p><strong>2. The Variational Simulation-Based Calibration (VSBC) Diagnostic</strong>: Given a Bayesian model <span class="math notranslate nohighlight">\(p(y, \theta) = p(y|\theta) p(\theta)\)</span>, if your variational inference proceedure is good at approximating the posterior <span class="math notranslate nohighlight">\(p(\theta|y)\)</span> then it should do well for most sets of data that is generated from the model <span class="math notranslate nohighlight">\(p(y, \theta)\)</span>.</p>
<p>We generate <span class="math notranslate nohighlight">\(M\)</span> sets of synthetic data from <span class="math notranslate nohighlight">\(p(y, \theta)\)</span>. For each set of the data we approximate the posterior <span class="math notranslate nohighlight">\(q_m(\theta)\)</span>. We then perform a calibration test on each variational approximation. This will reveal if your variational inference procedure is biased - produces approximation that are consistently flawed in some specific way.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="how-to-improve-approximate-inference">
<h1><span class="section-number">40. </span>How to Improve Approximate Inference<a class="headerlink" href="#how-to-improve-approximate-inference" title="Permalink to this heading">#</a></h1>
<section id="your-variational-approximation-sucks-can-you-fix-it">
<h2>Your Variational Approximation Sucks, Can You Fix It?<a class="headerlink" href="#your-variational-approximation-sucks-can-you-fix-it" title="Permalink to this heading">#</a></h2>
<p>The current research on improving variational inference can be categorize by which <strong>design choice</strong> each work tries to improve:</p>
<p><strong>1. Choice of Divergence:</strong> In Lab #5, you explored the draw-backs of fitting an approximate posterior <span class="math notranslate nohighlight">\(q\)</span> to the true posterior <span class="math notranslate nohighlight">\(p\)</span> using KL-divergence. There are a huge number of works that explore performing variational inference using other types of divergences, for example: <br>
<span class="math notranslate nohighlight">\(\quad\)</span> <strong>a.</strong> <a class="reference external" href="https://arxiv.org/abs/1511.03243">“Black-box <span class="math notranslate nohighlight">\(\alpha\)</span>-divergence Minimization”</a><br>
<span class="math notranslate nohighlight">\(\quad\)</span> <strong>b.</strong> <a class="reference external" href="https://arxiv.org/abs/1608.04471">“Stein Variational Gradient Descent”</a></p>
<p><strong>2. Choice of Variational Family:</strong> In Homework #0, you’ve seen that even for a simple Bayesian linear regression model, the model parameters were corrlated in the posterior. In Lab #7, you’ve seen that minimizing the KL-divergence to fit an isotropic Gaussian means that you can only capture one mode in the posterior. There are a huge number of works that explore using different types of variational families:<br>
<span class="math notranslate nohighlight">\(\quad\)</span> <strong>a.</strong> <a class="reference external" href="https://arxiv.org/abs/1505.05770">“Variational Inference with Normalizing Flows”</a><br>
<span class="math notranslate nohighlight">\(\quad\)</span> <strong>b.</strong> <a class="reference external" href="https://arxiv.org/abs/1511.06499">“The Variational Gaussian Process”</a><br></p>
<p><strong>3. Choice of Optimization Procedure:</strong> Even if your divergence measure and variational family are well-chosen, the optimization objective can still be non-convex! This means that your optimization procedure might return a <span class="math notranslate nohighlight">\(q\)</span> that is a only local-optimum. There are a large number of works that address how to jump out of local optima using SGD and some works that specifically address the optimization challenges of variational inference:<br>
<span class="math notranslate nohighlight">\(\quad\)</span> <strong>a.</strong> <a class="reference external" href="https://arxiv.org/abs/1705.08931">“Proximity Variational Inference”</a></p>
</section>
<section id="are-there-any-good-properties-of-variational-approximations-that-we-are-sure-about">
<h2>Are There Any Good Properties of Variational Approximations that We Are Sure About?<a class="headerlink" href="#are-there-any-good-properties-of-variational-approximations-that-we-are-sure-about" title="Permalink to this heading">#</a></h2>
<p>In <a class="reference external" href="https://arxiv.org/abs/1705.03439">“Frequentist Consistency of Variational Bayes”</a>, the authors prove that under <strong>certain assumptions</strong> on <span class="math notranslate nohighlight">\(p(\theta)\)</span> and <span class="math notranslate nohighlight">\(p(y|\theta)\)</span>:</p>
<ol class="arabic simple">
<li><p>as the number of observation increases, the variational approximation converges (in Total Variation distance) to the <span class="math notranslate nohighlight">\(q\)</span> that minimizes the KL-divergence to a normal distribution centered at the ground truth parameters <span class="math notranslate nohighlight">\(\theta_{\text{true}}\)</span> that generated the data.<br><br></p></li>
<li><p>the mean of the variational approximation is consistent and asymptoptically normal.</p></li>
</ol>
<p>Unfortunately, the assumptions required by the theorems <strong>do not hold for neural network likelihood models</strong>.</p>
</section>
<section id="why-is-inference-for-neural-networks-hard">
<h2>Why is Inference for Neural Networks Hard?<a class="headerlink" href="#why-is-inference-for-neural-networks-hard" title="Permalink to this heading">#</a></h2>
<p>Research on the likelihoods (and hence posteriors) of neural networks are beginning to give us ways of visualizing these high-dimensional functions using low-dimensional (3D) projections. <a class="reference external" href="https://losslandscape.com">Loss Landsacapes</a> represents some of the latest efforts at visualization:</p>
<img src="fig/loss.jpg" style="height:400px;" align="center"/></section>
<section id="it-s-weirder-than-you-can-imagine">
<h2>It’s Weirder Than You Can Imagine<a class="headerlink" href="#it-s-weirder-than-you-can-imagine" title="Permalink to this heading">#</a></h2>
<p>In <a class="reference external" href="https://arxiv.org/pdf/1910.03867.pdf">“Loss Landscape Sightseeing with Multi-Point Optimization”</a>, the authors show that neural network likelihoods (and thus posteriors) are so complicated that you can find a 2-D projection that can create any pattern you want:</p>
<img src="fig/loss2.jpg" style="height:250px;" align="center"/>
<p><strong>The lesson</strong>: take every low-dimensional visualization with a grain of salt (i.e. it far from accurately represents the entire landscape).</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="but-why-do-i-care">
<h1><span class="section-number">41. </span>But why do I care?<a class="headerlink" href="#but-why-do-i-care" title="Permalink to this heading">#</a></h1>
<section id="evaluation-of-variational-approximation-for-real-down-stream-tasks">
<h2>Evaluation of Variational Approximation for Real Down-stream Tasks<a class="headerlink" href="#evaluation-of-variational-approximation-for-real-down-stream-tasks" title="Permalink to this heading">#</a></h2>
<p>In practice, you may only care about the quality of your posterior approximation in so far as it affects model performance on your down-stream task. So what do we want from our machine learning or statistical models, especially when they are used in safety, or fairness critical applications (e.g. personalized medicine, health-care resource allocation, criminal justic systems)?</p>
<p>Most of us in the community agree that we want models that <em>1)</em> makes accurate predictions <em>2)</em> gives realistic estimates of its prective uncertainty. So that the model can be held-accountable by humans in the system. There are a number of subcomunities in ML that focus on studying the social impact of machine learning models as well as how to design models whose negative impact can be mitigated.</p>
<p><strong>a.</strong> <a class="reference external" href="https://arxiv.org/pdf/1606.06565.pdf">“Concrete Problems in AI Safety”</a><br>
<strong>b.</strong> <a class="reference external" href="https://papers.nips.cc/paper/7853-predict-responsibly-improving-fairness-and-accuracy-by-learning-to-defer.pdf">“Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer”</a></p>
</section>
<section id="predictiveness-of-the-variational-approximate-posterior">
<h2>Predictiveness of the Variational Approximate Posterior<a class="headerlink" href="#predictiveness-of-the-variational-approximate-posterior" title="Permalink to this heading">#</a></h2>
<p>We can check the predictiveness of our varational approximation of the posterior by sampling models from the posterior and then making predictions using these models by sampling from the likelihood. We then check that these predictions align well with observed data by:</p>
<ol class="arabic simple">
<li><p><strong>Visualization:</strong> visualizing the posterior predictive against the observed data. <em>This is generally impossible for high dimensional data.</em><br><br></p></li>
<li><p><strong>Log Marginal Data Likelihood:</strong> we compute the expected value of the log likelihood of the test data under our approximate posterior. <em>Log likelihood is only useful for comparing two different models, given a single model it is hard to say if a log likelihood value is “good enough”.</em><br><br></p></li>
<li><p><strong>Expected Mean Square Error and Accuracy:</strong> we compute the expected MSE (for regression) or accuracy (for classification) on test data under our approximate posterior. <em>While these metric frames model quality in concrete task related terms, they are each misleading when the data contains outliers or imbalanced classes.</em></p></li>
</ol>
</section>
<section id="quality-of-variational-approximate-posterior-predictive-uncertainty">
<h2>Quality of Variational Approximate Posterior Predictive Uncertainty<a class="headerlink" href="#quality-of-variational-approximate-posterior-predictive-uncertainty" title="Permalink to this heading">#</a></h2>
<p>We’ve argued in this course that good predictive uncertainty must involve an accurate assessment of both <em><strong>epistemic</strong></em> and <em><strong>aleatoric</strong></em> uncertainty. Since each type of uncertainty requires a different risk-management action in the down-stream task.</p>
<img src="fig/posterior_pred.jpg" style="height:210px;" align="center"/>
<p>Unfortunately, there isn’t a single good statistical metric for assessing the quality of the uncertainty of a model. “Good” epstemic uncertainty is especially hard to quantify. Rather than looking for statistical tests of uncertainty, some in the ML community advocate for assessing model uncertainty with respect to a set of benchmark down-stream tasks: <a class="reference external" href="https://github.com/OATML/bdl-benchmarks">Bayesian Deep Learning Benchmarks</a></p>
</section>
<section id="does-a-poor-posterior-approximation-imply-a-poor-posterior-predictive">
<h2>Does a Poor Posterior Approximation Imply a Poor Posterior Predictive?<a class="headerlink" href="#does-a-poor-posterior-approximation-imply-a-poor-posterior-predictive" title="Permalink to this heading">#</a></h2>
<p>You’ve seen in HW#7 that even with an HMC sampler that is far from converged, you were able to produce posterior predictives that aligned well with the data and had good epistemic and aleatoric uncertainty. In fact, a number of works are showing that by capturing a little piece (if it is the right piece) of the true posterior of a BNN, you are able to capture most of the variation you want in the posterior predictive.</p>
<p>In <a class="reference external" href="https://arxiv.org/pdf/1907.07504.pdf">“Subspace Inference for Bayesian Deep Learning”</a>, the authors provide toy examples where one obtains a posterior predictive distribution with good epistemic and aleatoric uncertainty by reducing a high dimensional parameter space to 2-dimensions and performing inference in the 2-dimensional subspace:
<img src="fig/posterior_pred2.jpg" style="height:210px;" align="center"/></p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="new-developments-in-deep-bayes">
<h1><span class="section-number">42. </span>New Developments in Deep Bayes<a class="headerlink" href="#new-developments-in-deep-bayes" title="Permalink to this heading">#</a></h1>
<section id="what-s-wrong-with-posterior-approximations-for-bnns">
<h2>What’s Wrong with Posterior Approximations for BNNs<a class="headerlink" href="#what-s-wrong-with-posterior-approximations-for-bnns" title="Permalink to this heading">#</a></h2>
<p><em><strong>(joint work with Jiayu Yao, Soumya Ghosh, Finale Doshi-Velez)</strong></em></p>
<p><strong>The motivation:</strong> Frequently, we introduce a new approximate inference method for BNNs based on our intuition of what properties of the true posterior are important to include in our approximate posterior. We then measure the <em><strong>log-likelihood</strong></em> of our learned model on test data.</p>
<p><strong>The idea:</strong> We evaluate the ability of a number of state-of-the-art approximate inference methods for BNN on synthetic data that can be visualized to see if various custom approximations of the posterior translates to desirable posterior predictives.</p>
<p>We also test if the commonly used evaluation metrics, like test log-likelihood, can distinguish high quality posterior predictves from poor quality ones.</p>
<p><em><strong>From:</strong></em> <a class="reference external" href="https://arxiv.org/pdf/1906.09686.pdf">Quality of Uncertainty Quantification for Bayesian Neural Network Inference</a></p>
</section>
<section id="what-did-we-learn">
<h2>What Did We Learn?<a class="headerlink" href="#what-did-we-learn" title="Permalink to this heading">#</a></h2>
<p><strong>Take-away:</strong> Metric like test log-likelihood measures how well the approximate posterior predictive aligns with the data, not how well it approximate the true posterior predictive.</p>
<img src="fig/cubic_compare.png" style="height:170px;" align="center"/>
<p><strong>Take-away:</strong> Training with data gaps and evaluating test likelihood can only catch problems if the true function is complex in these gaps.</p>
<img src="fig/complex_compare.png" style="height:110px;" align="center"/>
<p><strong>Take-away:</strong> Inference methods that specialize in approximating specific properties in the posterior do not necessarily produce desirable posterior predictives.</p>
</section>
<section id="what-s-wrong-with-the-predictions-from-mean-field-variational-posteriors-of-bnns">
<h2>What’s Wrong with the Predictions from Mean-Field Variational Posteriors of BNNs?<a class="headerlink" href="#what-s-wrong-with-the-predictions-from-mean-field-variational-posteriors-of-bnns" title="Permalink to this heading">#</a></h2>
<p><em><strong>(joint work with Beau Coker, Finale Doshi-Velez)</strong></em></p>
<p>The problem with mean-field VI for BNNs isn’t just with the variance. In <a class="reference external" href="https://arxiv.org/pdf/2106.07052.pdf">Wide Mean-Field Variational Bayesian Neural Networks Ignore the Data</a>. we show that as the network width becomes wider, the posterior predictive mean ignores the data completely and learns a constant (flat) function!</p>
<img src="fig/widebnn.png" style="height:300px;" align="center"/>
<p>The fact that the posterior predictive mean of mean-field variational posteriors of wide BNNs <em><strong>underfit</strong></em> the data has been observed empirically in <a class="reference external" href="https://arxiv.org/abs/1801.06230">Overpruning in Variational Bayesian Neural Networks</a>.</p>
</section>
<section id="relationships-between-deep-ensembles-and-bayesian-neural-networks">
<h2>Relationships Between Deep Ensembles and Bayesian Neural Networks<a class="headerlink" href="#relationships-between-deep-ensembles-and-bayesian-neural-networks" title="Permalink to this heading">#</a></h2>
<p>Althhough we’ve been thinking about ensembles and Bayesian models as belonging to a dichotomy (frequentist vs Bayesian statistics), in papers like <a class="reference external" href="https://openreview.net/pdf?id=BJlahxHYDS">Conservative Uncertainty Estimation By Fitting Prior Networks</a> and <a class="reference external" href="https://arxiv.org/abs/2106.11642">Repulsive Deep Ensembles are Bayesian</a>, we see that ensembles and Bayesian models have a deep relationship.</p>
<p><strong>Take-away:</strong> In fact, some ensembles can be interpreted as collections of samples from a corresponding Bayesian model!</p>
</section>
<section id="alternative-models-for-uncertainty-quantification">
<h2>Alternative Models for Uncertainty Quantification<a class="headerlink" href="#alternative-models-for-uncertainty-quantification" title="Permalink to this heading">#</a></h2>
<p>Although mean-field VI is touted as a fast way of performing inference on BNNs, they are still hard to scale to truly large networks. For this reason, alternative deep Bayesian models have been gaining popularity. <strong>Neural Linear Models</strong> is a model that learns deterministic weights for an NN except for the last layer, where we place priors and perform exact Bayesian inference:</p>
<img src="fig/Unknown-20.png" style="height:280px;" align="center"/>
<p><em><strong>From:</strong></em> <a class="reference external" href="https://arxiv.org/pdf/2006.11695.pdf">Learned Uncertainty-Aware (LUNA) Bases for Bayesian Regression using Multi-Headed Auxiliary Networks</a></p>
</section>
<section id="predictive-uncertainties-of-alternative-deep-bayesian-models-may-not-be-better">
<h2>Predictive Uncertainties of Alternative Deep Bayesian Models May Not be Better<a class="headerlink" href="#predictive-uncertainties-of-alternative-deep-bayesian-models-may-not-be-better" title="Permalink to this heading">#</a></h2>
<p><em><strong>(joint work with Sujay Thakur, Cooper Lorsung, Yaniv Yacoby, Finale Doshi-Velez)</strong></em></p>
<p>In <a class="reference external" href="https://arxiv.org/pdf/2006.11695.pdf">Learned Uncertainty-Aware (LUNA) Bases for Bayesian Regression using Multi-Headed Auxiliary Networks</a>, we show that the posterior predictive uncertainty of NLMs are not what we might want. The problem has a lot to do with how we typically train neural networks.</p>
<img src="fig/Unknown-18.png" style="height:270px;" align="center"/>
</section>
<section id="what-uncertainties-do-we-need-in-deep-learning">
<h2>What Uncertainties Do We Need in Deep Learning?<a class="headerlink" href="#what-uncertainties-do-we-need-in-deep-learning" title="Permalink to this heading">#</a></h2>
<p>More and more folks in the Deep Bayes community is coming to the conclusion that the quality of uncertainty estimation can only be assessed in reference to a specific down-stream task, e.g. active learning, continual learning, Bayesian optimization, out of distribution detection, learning to defer (rejection learning), model interpretation etc.</p>
<img src="fig/bayesopt.png" style="height:350px;" align="center"/>
<p><strong>Take-away:</strong> There is no universal definition of or metric for “good” uncertainty - “good” uncertainty is uncertainty that is useful for the task.</p>
<p><strong>Take-away:</strong> Uncertainty estimation that is good for one task might be bad for another!</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="lecture_18_notes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">35. </span>Lecture #18: Automatic Differentiation</p>
      </div>
    </a>
    <a class="right-next"
       href="lecture_20_notes.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">43. </span>Lecture #20: Variational Autoencoders</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">38. Lecture #19: Variational Inference in Context</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#outline">Outline</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-evaluate-approximate-inference">39. How to Evaluate Approximate Inference</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-good-is-your-variational-approximation-of-the-true-posterior">How Good is Your Variational Approximation of the True Posterior?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alternative-posterior-evaluation-metrics">Alternative Posterior Evaluation Metrics</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-improve-approximate-inference">40. How to Improve Approximate Inference</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#your-variational-approximation-sucks-can-you-fix-it">Your Variational Approximation Sucks, Can You Fix It?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#are-there-any-good-properties-of-variational-approximations-that-we-are-sure-about">Are There Any Good Properties of Variational Approximations that We Are Sure About?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-is-inference-for-neural-networks-hard">Why is Inference for Neural Networks Hard?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#it-s-weirder-than-you-can-imagine">It’s Weirder Than You Can Imagine</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#but-why-do-i-care">41. But why do I care?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-of-variational-approximation-for-real-down-stream-tasks">Evaluation of Variational Approximation for Real Down-stream Tasks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictiveness-of-the-variational-approximate-posterior">Predictiveness of the Variational Approximate Posterior</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quality-of-variational-approximate-posterior-predictive-uncertainty">Quality of Variational Approximate Posterior Predictive Uncertainty</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#does-a-poor-posterior-approximation-imply-a-poor-posterior-predictive">Does a Poor Posterior Approximation Imply a Poor Posterior Predictive?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#new-developments-in-deep-bayes">42. New Developments in Deep Bayes</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-s-wrong-with-posterior-approximations-for-bnns">What’s Wrong with Posterior Approximations for BNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-did-we-learn">What Did We Learn?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-s-wrong-with-the-predictions-from-mean-field-variational-posteriors-of-bnns">What’s Wrong with the Predictions from Mean-Field Variational Posteriors of BNNs?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relationships-between-deep-ensembles-and-bayesian-neural-networks">Relationships Between Deep Ensembles and Bayesian Neural Networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alternative-models-for-uncertainty-quantification">Alternative Models for Uncertainty Quantification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictive-uncertainties-of-alternative-deep-bayesian-models-may-not-be-better">Predictive Uncertainties of Alternative Deep Bayesian Models May Not be Better</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-uncertainties-do-we-need-in-deep-learning">What Uncertainties Do We Need in Deep Learning?</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yaniv Yacoby
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>