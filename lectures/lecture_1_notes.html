

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>1. Lecture #1: Course Overview &#8212; Probabilistic Foundations of Machine Learning (CS349)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/lecture_1_notes';</script>
    <link rel="canonical" href="https://mogu-lab.github.io/cs349-fall-2024/lectures/lecture_1_notes.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. Lecture #2: Maximimum Likelihood Estimation" href="lecture_2_notes.html" />
    <link rel="prev" title="Probabilistic Foundations of Machine Learning" href="../index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Probabilistic Foundations of Machine Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Exact Inference</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">1. Lecture #1: Course Overview</a></li>





<li class="toctree-l1"><a class="reference internal" href="lecture_2_notes.html">7. Lecture #2: Maximimum Likelihood Estimation</a></li>






<li class="toctree-l1"><a class="reference internal" href="lecture_3_notes.html">14. Lecture #3: Bayesian Modeling</a></li>






<li class="toctree-l1"><a class="reference internal" href="lecture_4_notes.html">21. Lecture #4: Bayesian versus Frequentist Inference</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Sampling-Based Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture_5_notes.html">1. Lecture #5: Sampling for Posterior Simulation</a></li>





<li class="toctree-l1"><a class="reference internal" href="lecture_6_notes.html">7. Lecture #6: Monte Carlo Integration</a></li>






<li class="toctree-l1"><a class="reference internal" href="lecture_7_notes.html">14. Lecture #7: Markov Chain Monte Carlo</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_8_notes.html">18. Lecture #8: Metropolis-Hastings and Gibbs</a></li>




<li class="toctree-l1"><a class="reference internal" href="lecture_9_notes.html">23. Lecture #9: Latent Variable Models and MLE</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Gradient-Based Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture_10_notes.html">1. Lecture #10: Bayesian Latent Variable Models and Variational Inference</a></li>

<li class="toctree-l1"><a class="reference internal" href="lecture_11_notes.html">3. Lecture #11: Hierarchical Models</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_12_notes.html">7. Lecture #12: Logistic Regression and Gradient Descent</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_13_notes.html">11. Lecture #13: Stochastic Gradient Descent and Simulated Annealing</a></li>





<li class="toctree-l1"><a class="reference internal" href="lecture_14_notes.html">17. Lecture #14: Hamiltonian Monte Carlo</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_15_notes.html">21. Lecture #15: Parallel Tempering and Stochastic HMC</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_16_notes.html">25. Lecture #16: Neural Network Models for Regression</a></li>





<li class="toctree-l1"><a class="reference internal" href="lecture_17_notes.html">31. Lecture #17: Black-box Variational Inference</a></li>



<li class="toctree-l1"><a class="reference internal" href="lecture_18_notes.html">35. Lecture #18: Automatic Differentiation</a></li>


<li class="toctree-l1"><a class="reference internal" href="lecture_19_notes.html">38. Lecture #19: Variational Inference in Context</a></li>




<li class="toctree-l1"><a class="reference internal" href="lecture_20_notes.html">43. Lecture #20: Variational Autoencoders</a></li>


<li class="toctree-l1"><a class="reference internal" href="lecture_21_notes.html">46. Lecture #21: Implementation of Variational Autoencoders</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/mogu-lab/cs349-fall-2024/blob/master/lectures/lecture_1_notes.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li><a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fmogu-lab%2Fcs349-fall-2024%2Fblob%2Fmaster%2Flectures/lecture_1_notes.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onDeepnote"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_deepnote.svg">
  </span>
<span class="btn__text-container">Deepnote</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lectures/lecture_1_notes.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture #1: Course Overview</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">1. Lecture #1: Course Overview</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#outline">Outline</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-this-course-about">2. What is this course about?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-model-patterns-in-data">How Do We Model Patterns in Data?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">How Do We Model Patterns in Data?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-model">What is a Model?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">What is a Model?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-notion-of-error">A Notion of Error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-quantify-the-overall-error">How do we quantify the overall error?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-fitting">Model Fitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-in-sklearn">Linear Regression in <code class="docutils literal notranslate"><span class="pre">sklearn</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-statistical-model">What is a Statistical Model?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-statistical-model-for-regression">A Statistical Model for Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-quantify-fitness">How Do We Quantify Fitness?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Model Fitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximimum-likelihood-and-minimum-mean-square-error">Maximimum Likelihood and Minimum Mean Square Error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-evaluation">Model Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-interpretation">Model Interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-bayesian-model">What is a Bayesian Model?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-inference">Model Inference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-linear-regression">Bayesian Linear Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-versus-frequentist-uncertainty">Bayesian versus Frequentist Uncertainty</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Model Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-is-this-hard">Why is This Hard?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#is-accuracy-enough">Is Accuracy Enough?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-kinds-of-predictive-uncertainty-do-we-want">What Kinds of Predictive Uncertainty Do We Want?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">What Kinds of Predictive Uncertainty Do We Want?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#so-now-you-have-predictive-uncertainties-what-are-you-gonna-do-with-them">So Now You Have Predictive Uncertainties, What Are You Gonna Do With Them?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-explain-decisions-of-machine-learning-models">How Do We Explain Decisions of Machine Learning Models?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-you-communicate-ml-predictions-and-does-it-matter">How Do You Communicate ML Predictions, And Does It Matter?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-interactions-do-we-need-to-think-about-when-we-design-ml-models">What Interactions Do We Need to Think About When We Design ML Models?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-promises-of-human-ai-systems">The Promises of Human + AI Systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-perils-of-human-ai-systems">The Perils of Human + AI Systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-potential-social-benifits-of-machine-learning">The Potential Social Benifits of Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-negative-social-impacts-of-machine-learning">The Negative Social Impacts of Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-is-this-happening">Why Is This Happening?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alternative-problem-solving-frameworks-for-machine-learning">Alternative Problem Solving Frameworks for Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-much-more-than-accuracy">Machine Learning: Much More Than Accuracy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-am207">What is AM207?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#what-technologies-do-you-need-for-this-class">3. What technologies do you need for this class?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-meetings">For Meetings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gather-town-s-virtual-environment"><code class="docutils literal notranslate"><span class="pre">gather.town</span></code>’s Virtual Environment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-completing-assignments">For Completing Assignments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-in-class-exercises">For In-Class Exercises</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#how-is-this-course-structured">4. How is this course structured?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graded-components">Graded Components</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#policies">Policies</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-i-get-help-for-the-course">5. How do I get help for the course?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teaching-staff">Teaching Staff</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tf-office-hours">TF Office Hours</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instructor-office-hours">Instructor Office Hours</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#piazza">Piazza</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#final-words-of-advice">6. Final Words of Advice</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-we-ve-changed-am207">How We’ve Changed AM207</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-we-are-asking-from-you">What We are Asking From You</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-work-in-teams">How to Work in Teams</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-1-course-overview">
<h1><span class="section-number">1. </span>Lecture #1: Course Overview<a class="headerlink" href="#lecture-1-course-overview" title="Permalink to this heading">#</a></h1>
<section id="am-207-advanced-scientific-computing">
<h2>AM 207: Advanced Scientific Computing<a class="headerlink" href="#am-207-advanced-scientific-computing" title="Permalink to this heading">#</a></h2>
<section id="stochastic-methods-for-data-analysis-inference-and-optimization">
<h3>Stochastic Methods for Data Analysis, Inference and Optimization<a class="headerlink" href="#stochastic-methods-for-data-analysis-inference-and-optimization" title="Permalink to this heading">#</a></h3>
</section>
<section id="fall-2021">
<h3>Fall, 2021<a class="headerlink" href="#fall-2021" title="Permalink to this heading">#</a></h3>
<img src="fig/logos.jpg" style="height:150px;"><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="outline">
<h2>Outline<a class="headerlink" href="#outline" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>What is this course about?</p></li>
<li><p>What technology do I need?</p></li>
<li><p>How is this course structured?</p></li>
<li><p>How do I get help for the course?</p></li>
<li><p>Final words of advice</p></li>
</ol>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="what-is-this-course-about">
<h1><span class="section-number">2. </span>What is this course about?<a class="headerlink" href="#what-is-this-course-about" title="Permalink to this heading">#</a></h1>
<section id="how-do-we-model-patterns-in-data">
<h2>How Do We Model Patterns in Data?<a class="headerlink" href="#how-do-we-model-patterns-in-data" title="Permalink to this heading">#</a></h2>
<p>This is a scatter plot of home prices vs square footage of some homes in southern California.</p>
<img src="fig/fig32.jpg" style="height:350px;">
<p>Can you see any patterns or trends?</p>
</section>
<section id="id1">
<h2>How Do We Model Patterns in Data?<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>We see that as <strong>square footage</strong> increases, so does <strong>price</strong>.</p>
<img src="fig/fig32.jpg" style="height:350px;">
<p>But what is a precise, mathematical description of this relationship?</p>
</section>
<section id="what-is-a-model">
<h2>What is a Model?<a class="headerlink" href="#what-is-a-model" title="Permalink to this heading">#</a></h2>
<p>Building a model to capture a hypothesized relationship means we predict the value of one group of attributes using another group.</p>
<p>This prediction problem is called <em><strong>regression</strong></em>, the attribute we are trying to predict (e.g.price) is called the <em><strong>outcome</strong></em> or the <em><strong>target</strong></em>, denoted by <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>The group of attributes (e.g. square footage) we use to make the prediction is called the <em><strong>covariates</strong></em>, denoted by <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>A <em><strong>regression model</strong></em> is a mathematical function, <span class="math notranslate nohighlight">\(f(x)\)</span>, that predicts the target. We denote our prediction by <span class="math notranslate nohighlight">\(\hat{y} = f(x)\)</span>.</p>
</section>
<section id="id2">
<h2>What is a Model?<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>We conjectured that the model for this data is a line: <span class="math notranslate nohighlight">\(\hat{y} = f(x) = w_1x + w_0\)</span>.</p>
<img src="fig/fig33.jpg" style="height:350px;">
<p>But which line fits the data best?</p>
</section>
<section id="a-notion-of-error">
<h2>A Notion of Error<a class="headerlink" href="#a-notion-of-error" title="Permalink to this heading">#</a></h2>
<p>An <em><strong>absolute residual</strong></em> is the absolute difference between the actual price of a home and the price predicted by the line for a given square footage:
$<span class="math notranslate nohighlight">\(
\mathtt{Residual}_n = y_n - \hat{y}_n
\)</span>$</p>
<img src="fig/fig34.jpg" style="height:350px;"></section>
<section id="how-do-we-quantify-the-overall-error">
<h2>How do we quantify the overall error?<a class="headerlink" href="#how-do-we-quantify-the-overall-error" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>(Max absolute deviation)</strong> Count only the biggest “error”
$<span class="math notranslate nohighlight">\(
\max_n |y_n - \hat{y}_n| 
\)</span>$</p></li>
<li><p><strong>(Sum of absolute deviations)</strong> Add up all the “errors”
$<span class="math notranslate nohighlight">\(
\sum_n |y_n - \hat{y}_n| 
\)</span>$</p></li>
<li><p><strong>(Sum of squared errors)</strong> Add up the squares of the “errors”
$<span class="math notranslate nohighlight">\(
\sum_n |y_n - \hat{y}_n|^2 
\)</span>$</p></li>
<li><p><strong>(Mean squared errors)</strong> We can also average the squared “errors”.
$<span class="math notranslate nohighlight">\(
\frac{1}{N}\sum_{n=1}^N |y_n - \hat{y}_n|^2 
\)</span>$</p></li>
</ol>
<p>Again, <span class="math notranslate nohighlight">\(y_n\)</span> is the observed target, <span class="math notranslate nohighlight">\(\hat{y}_n\)</span> is the predicted target.</p>
</section>
<section id="model-fitting">
<h2>Model Fitting<a class="headerlink" href="#model-fitting" title="Permalink to this heading">#</a></h2>
<p><strong>Question:</strong> What do we mean by choosing “best” line, <span class="math notranslate nohighlight">\(\hat{y} = w_1x + w_0\)</span>?</p>
<p>The <em><strong>model fitting</strong></em> process:</p>
<ol class="arabic simple">
<li><p><em>Choose</em> an overall error metric. This metric is called the <em><strong>loss function</strong></em> or <em><strong>training objective</strong></em>:
$<span class="math notranslate nohighlight">\(
\mathcal{L}(w_1, w_0) = \frac{1}{N}\sum_{n=1}^N |y_n - (w_1x_n + w_0)|^2, \quad\quad \text{(Mean Squared Error Loss)}
\)</span>$</p></li>
<li><p>Set up the problem of finding coefficients or <em><strong>parameters</strong></em>, <span class="math notranslate nohighlight">\(w_0, w_1\)</span>, such that the loss function is <strong>minimized</strong>:
$<span class="math notranslate nohighlight">\(
\underset{w_0, w_1}{\mathrm{argmin}}\mathcal{L}(w_1, w_0) = \underset{w_0, w_1}{\mathrm{argmin}}\frac{1}{N}\sum_{n=1}^N |y_n - (w_1x_n + w_0)|^2 
\)</span>$</p></li>
<li><p>Choose a method of minimizing the loss function.</p></li>
</ol>
<p><strong>Note:</strong> For linear regression, we can minimize <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> analytically. We cannot do this for every model!</p>
</section>
<section id="linear-regression-in-sklearn">
<h2>Linear Regression in <code class="docutils literal notranslate"><span class="pre">sklearn</span></code><a class="headerlink" href="#linear-regression-in-sklearn" title="Permalink to this heading">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># import the LinearRegression model from the sklearn library</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># make an instance of the linear regression model</span>
<span class="n">regression</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># find the coefficients for the line that minimizes mean squared error</span>
<span class="n">regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="what-is-a-statistical-model">
<h2>What is a Statistical Model?<a class="headerlink" href="#what-is-a-statistical-model" title="Permalink to this heading">#</a></h2>
<p>Perhaps our <strong>choice</strong> of an overall error can be less arbitrary if we explain how, we believe, the residual arise.</p>
<p><strong>Belief:</strong> The theoretical relationship between price and square footage (<span class="math notranslate nohighlight">\(x\)</span>) is given by <span class="math notranslate nohighlight">\(f(x)\)</span>. But, in real-life, due to unpredictable circumstances observed prices (<span class="math notranslate nohighlight">\(y\)</span>) differ from <span class="math notranslate nohighlight">\(f(x)\)</span> by some random amount, <span class="math notranslate nohighlight">\(\epsilon\)</span>, called <em><strong>noise</strong></em>:
$<span class="math notranslate nohighlight">\(
y = f(x) + \epsilon, \quad \epsilon \sim p(\epsilon)
\)</span>$</p>
<p>A <em><strong>statistical model</strong></em> is one that explicitly accounts for uncertainty or randomness.</p>
</section>
<section id="a-statistical-model-for-regression">
<h2>A Statistical Model for Regression<a class="headerlink" href="#a-statistical-model-for-regression" title="Permalink to this heading">#</a></h2>
<p>Let us <em>assume</em> that (1) the underlying relationship between price and square footage <span class="math notranslate nohighlight">\(x\)</span> is given by <span class="math notranslate nohighlight">\(f(x) = w_1x + w_0\)</span>; (2) that the observed price <span class="math notranslate nohighlight">\(y\)</span> deviates from <span class="math notranslate nohighlight">\(f(x)\)</span> by a random amount that is independent from <span class="math notranslate nohighlight">\(x\)</span> and is distributed as <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
y = f(x) + \epsilon, \quad \epsilon \overset{\text{iid}}{\sim} \mathcal{N}(0, 1)
\]</div>
<p>Note that <span class="math notranslate nohighlight">\(y\)</span> is now a random variable with distribution <span class="math notranslate nohighlight">\(\mathcal{N}(f(x), 1)\)</span>, denoted by <span class="math notranslate nohighlight">\(p(y|x, w_1, w_0)\)</span>.</p>
</section>
<section id="how-do-we-quantify-fitness">
<h2>How Do We Quantify Fitness?<a class="headerlink" href="#how-do-we-quantify-fitness" title="Permalink to this heading">#</a></h2>
<p>Given our statistical model, a natural way for quantifying how well <span class="math notranslate nohighlight">\(f(x) = w_1x + w_0\)</span> fits the data is by checking how likely our choice of <span class="math notranslate nohighlight">\(w_0\)</span> and <span class="math notranslate nohighlight">\(w_1\)</span> makes the observed data, i.e. compute
$<span class="math notranslate nohighlight">\(
\mathcal{L}(w_1, w_0) = \prod_{n=1}^N p(y_n|x_n, w_1, w_0).
\)</span><span class="math notranslate nohighlight">\(
The function \)</span>\mathcal{L}(w_1, w_0)$ is called the <em><strong>likelihood function</strong></em>.</p>
<p><strong>Exercise:</strong> suppose we have two models, <span class="math notranslate nohighlight">\(f(x) = 3x + 2\)</span> and <span class="math notranslate nohighlight">\(f(x) = 10 - x\)</span>. Suppose that <span class="math notranslate nohighlight">\(\mathcal{L}(w_1=3, w_0=2) = 10.2\)</span> and <span class="math notranslate nohighlight">\(\mathcal{L}(w_1=-1, w_0=10) = 0.002\)</span>. Which model is a better fit for the data and why?</p>
</section>
<section id="id3">
<h2>Model Fitting<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h2>
<p><strong>Question:</strong> What do we mean by choosing “best” line, <span class="math notranslate nohighlight">\(\hat{y} = f(x) = w_1x + w_0\)</span>?</p>
<p>The <em><strong>model fitting</strong></em> process:</p>
<ol class="arabic simple">
<li><p><em>Choose</em> a method of estimation for statistical models. For example, set up the problem of finding coefficients or <em><strong>parameters</strong></em>, <span class="math notranslate nohighlight">\(w_0, w_1\)</span>, such that the likelihood of the data is <strong>maximized</strong>:
$<span class="math notranslate nohighlight">\(
\mathrm{argmax}_{w_0, w_1}\mathcal{L}(w_1, w_0) = \mathrm{argmax}_{w_0, w_1}\prod_{n=1}^N p(y_n|x_n, w_1, w_0) 
\)</span>$</p></li>
<li><p>Choose a method of computing the estimate. For example, choose a way to maximize the likelihood.</p></li>
</ol>
</section>
<section id="maximimum-likelihood-and-minimum-mean-square-error">
<h2>Maximimum Likelihood and Minimum Mean Square Error<a class="headerlink" href="#maximimum-likelihood-and-minimum-mean-square-error" title="Permalink to this heading">#</a></h2>
<p>Given our statistical model
$<span class="math notranslate nohighlight">\(
y = f(x) + \epsilon, \quad \epsilon \overset{\text{iid}}{\sim} \mathcal{N}(0, 1)
\)</span><span class="math notranslate nohighlight">\(
Maximimizing the likelihood is equivalent to minimizing the mean squared error:
\)</span><span class="math notranslate nohighlight">\(
\mathrm{argmax}_{w_0, w_1}\prod_{n=1}^N p(y_n|x_n, w_1, w_0) \equiv \mathrm{argmin}_{w_0, w_1}\frac{1}{N}\sum_{i=1}^N |y_i - (w_1x_1 + w_0)|^2 
\)</span>$</p>
<p><em>Hint: note that</em>
$<span class="math notranslate nohighlight">\(\prod_{n=1}^Np(y_n|x_n, w_1, w_0) = \frac{1}{\sqrt{2\pi 1}^N} \exp\left\{-\frac{\sum_{i=1}^N(y_n - (w_1x_n + w_0))^2}{2 * 1} \right\}\)</span><span class="math notranslate nohighlight">\( 
*and that*
\)</span><span class="math notranslate nohighlight">\(\log p(y|x, w_1, w_0) = N\log\left(\frac{1}{\sqrt{2\pi 1}}\right) - \frac{\sum_{i=1}^N(y_n - (w_1x_n + w_0))^2}{2 * 1} \)</span>$</p>
</section>
<section id="model-evaluation">
<h2>Model Evaluation<a class="headerlink" href="#model-evaluation" title="Permalink to this heading">#</a></h2>
<p>After fitting the model (finding coefficients that maximizes the likelihood or that minimizes the loss function), we need to <strong>check the error or residuals of the model</strong>. Why?</p>
<img src="fig/fig36.jpg" style="height:300px;">
<p>Working with statistical models gives us an advantage in model evaluation, can you see why?</p>
</section>
<section id="model-interpretation">
<h2>Model Interpretation<a class="headerlink" href="#model-interpretation" title="Permalink to this heading">#</a></h2>
<p>In addition to evaluating our model on training and testing data, we must also examine the coefficients themselves. Why?</p>
<img src="fig/fig35.jpg" style="height:300px;">
</section>
<section id="what-is-a-bayesian-model">
<h2>What is a Bayesian Model?<a class="headerlink" href="#what-is-a-bayesian-model" title="Permalink to this heading">#</a></h2>
<p>In addition to a statistical model that explains trends <span class="math notranslate nohighlight">\(f(x)\)</span> and observation noise <span class="math notranslate nohighlight">\(\epsilon\)</span>, we also want to incorporate our <strong>prior beliefs</strong> about the model. Finally, we want to obtain a measure of <strong>uncertainty</strong> for our parameter estimates as well as our predictions.</p>
<p>Our Bayesian model for linear regression:
\begin{aligned}
y &amp;= w_1x + w_0 +\epsilon\
\epsilon &amp;\overset{\text{iid}}{\sim} \mathcal{N}(0, 1)\
w_1 &amp;\sim p(w_1)\
w_0 &amp;\sim p(w_0)\
\end{aligned}</p>
<p>where the prior <span class="math notranslate nohighlight">\(p(w_i)\)</span> may express that we want <span class="math notranslate nohighlight">\(w_i\)</span> to be non-negative and not too large.</p>
</section>
<section id="model-inference">
<h2>Model Inference<a class="headerlink" href="#model-inference" title="Permalink to this heading">#</a></h2>
<p>How do we “learn” the parameters in a Bayesian model?</p>
<p>Baye’s Rule gives us a way to obtain a distribution over <span class="math notranslate nohighlight">\(w_1, w_0\)</span> given the data <span class="math notranslate nohighlight">\((x_1, y_1), \ldots, (x_N, y_N)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
p(w_1, w_0 | x_1, \ldots, x_N, y_1, \ldots, y_N) \propto \underbrace{\left(\prod_{n=1}^N p(y_n|x_n, w_1, w_0)\right)}_{\text{How well params fit the data}} \underbrace{p(w_1)p(w_0)}_{\text{How well the params fit priors}}
\]</div>
<p>The distirbution <span class="math notranslate nohighlight">\(p(w_1, w_0 | x_1, \ldots, x_N, y_1, \ldots, y_N)\)</span> is called the <em><strong>poseterior</strong></em> and gives the likelihood of a pair of parameters <span class="math notranslate nohighlight">\(w_1, w_0\)</span> given the observed data.</p>
<p>We see that the likelihood score of the parameters under the posterior is influence both by how well the parameters fit the data and how well the parameters fit our prior beliefs.</p>
</section>
<section id="bayesian-linear-regression">
<h2>Bayesian Linear Regression<a class="headerlink" href="#bayesian-linear-regression" title="Permalink to this heading">#</a></h2>
<p>When we choose normal priors for the parameters in a linear regression model, for example,</p>
<p>\begin{aligned}
y &amp;=  w_1x + w_0 + \epsilon\
\epsilon &amp;\overset{\text{iid}}{\sim} \mathcal{N}(0, 1)\
w_1 &amp;\sim \mathcal{N}(0, 0.5)\
w_0 &amp;\sim \mathcal{N}(0, 1)\
\end{aligned}</p>
<p>The posterior <span class="math notranslate nohighlight">\(p(w_1, w_0 | x_1, \ldots, x_N, y_1, \ldots, y_N)\)</span> is again a (multivariate) normal distribution, <span class="math notranslate nohighlight">\(\mathcal{N}(\mu, \Sigma)\)</span>, and we can derive closed form solutions for <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\Sigma\)</span>.</p>
<p>Why is this observation important?</p>
</section>
<section id="bayesian-versus-frequentist-uncertainty">
<h2>Bayesian versus Frequentist Uncertainty<a class="headerlink" href="#bayesian-versus-frequentist-uncertainty" title="Permalink to this heading">#</a></h2>
<p>The main advantage of the Bayesian approach is that rather than obtaining a single “best” estimate of the model parameters, the posterior gives us a distribution over a set of plausible model parameters (with some models being more likely than others).</p>
<p>The spread of this distribution over plausible models naturally gives us a way to quantify our <strong>uncertainty</strong> over which is the “best” model. When the spread is wide (when many very different models are equally very likely), our uncertainty is high. When the spread is narrow (when all likely models look very similar), our uncertainty is low.</p>
<p>We can also obtain a sense of uncertainty over models using the non-Bayesian probabilistic model. Typically, we randomly sample sets of training data point from the training data, on each set, we compute the MLE of the model parameters. This process is called <strong>bootstrapping</strong>.</p>
<p>In HW#0 you will compare the uncertainties from the posteriors of Bayesian models with those from bootstrapping maximum likelihood models.</p>
</section>
<section id="id4">
<h2>Model Evaluation<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h2>
<p>With a Bayesian model we get a distribution <span class="math notranslate nohighlight">\(p(w_1, w_0| \text{Data})\)</span> over likely functions rather than a single function <span class="math notranslate nohighlight">\(f(x) = w_1x + w_0\)</span>. How then do we evaluate the “error” of model?</p>
<p>In the Maximum Likelihood model, we can explicitly check the correctness of our assumptions by checking the distribution of the residuals. How do we criticize a Bayesian model?</p>
</section>
<section id="why-is-this-hard">
<h2>Why is This Hard?<a class="headerlink" href="#why-is-this-hard" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Stating that our goal is to maximize likelihood or minimize MSE is easy. Finding the optimal parameters is often very hard (especially if <span class="math notranslate nohighlight">\(f(x)\)</span> is not linear, but rather, a complex function represented by a neural network).
<br><br></p></li>
<li><p>If we choose more “interesting” or “expressive” priors, or if we choose more complex <span class="math notranslate nohighlight">\(f(x)\)</span>, then it is often the case that the posterior cannot be computed in closed form.</p></li>
</ol>
<p>Both model fitting and inference requires sophisticated algorithms derived from deep theoretical understanding of the models.</p>
</section>
<section id="is-accuracy-enough">
<h2>Is Accuracy Enough?<a class="headerlink" href="#is-accuracy-enough" title="Permalink to this heading">#</a></h2>
<p>We mentioned that we can get predictive uncertainty from maximum likelihood models by bootstrapping and that Bayesian models naturally give us a sense of predictive uncertainty. These are useful properties that are important for real-life applications.</p>
<p>When machine learning models are applied to safety-critical, risk-adverse domains such as precision health care, financial and criminal justice systems, reliable measurements of a model’s predictive uncertainty may be as crucial as correctness of its predictions.</p>
<img src="./fig/health.jpg" style="height: 300px;" align="center"/></section>
<section id="what-kinds-of-predictive-uncertainty-do-we-want">
<h2>What Kinds of Predictive Uncertainty Do We Want?<a class="headerlink" href="#what-kinds-of-predictive-uncertainty-do-we-want" title="Permalink to this heading">#</a></h2>
<p>Predictive uncertainty helps us quantify risk in down-stream tasks:</p>
<img src="fig/dosage.png" style="height:100px;" align="center"/>
<p>We also care about the <em><strong>source of uncertainty</strong></em>:
<img src="fig/dosage2.png" style="height:100px;" align="center"/></p>
</section>
<section id="id5">
<h2>What Kinds of Predictive Uncertainty Do We Want?<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h2>
<p>What information about the data/model do we want our uncertainties to capture?</p>
<p><strong>Epistemic Uncertainty</strong> asks which function fits our data. Epistemic uncertainty arises due to small number of samples across all scenarios. This can be reduced by more samples!</p>
<p><strong>Aleatoric Uncertainty:</strong> asks what is the level of randomness that underlies the data generation process. This is irreducible.<br><br></p>
<img src="fig/uncertainty.png" style="height:250px;" align="center"/></section>
<section id="so-now-you-have-predictive-uncertainties-what-are-you-gonna-do-with-them">
<h2>So Now You Have Predictive Uncertainties, What Are You Gonna Do With Them?<a class="headerlink" href="#so-now-you-have-predictive-uncertainties-what-are-you-gonna-do-with-them" title="Permalink to this heading">#</a></h2>
<p>In <span class="xref myst"><em>Efficient Out-of-Distribution Detection in Digital Pathology Using Multi-Head Convolutional Neural Networks</em></span> (Linmans et al, Medical Imaging with Deep Learning 2020), the authors train an uncertainty-aware neural network model to detect breast cancer metastasis.</p>
<p>The epistemic uncertainty is used during test time to detect new types of breast tissue images that were not included in the training data. Classification of these novel types of images can be deferred to a human.</p>
<p>Unfamiliar types were caught at test time with <strong>AUC of .98</strong>.</p>
<img src="./fig/BreastPathQ.png" style="height: 350px;" align="center"/></section>
<section id="how-do-we-explain-decisions-of-machine-learning-models">
<h2>How Do We Explain Decisions of Machine Learning Models?<a class="headerlink" href="#how-do-we-explain-decisions-of-machine-learning-models" title="Permalink to this heading">#</a></h2>
<p>In order for human decision makers to interact with machine learning models meaningfully, we need these models to be <strong>interpretable</strong>. But explanation complex models is difficult.</p>
<img src="fig/slide14.png" style="height:350px;" align="center"/></section>
<section id="how-do-you-communicate-ml-predictions-and-does-it-matter">
<h2>How Do You Communicate ML Predictions, And Does It Matter?<a class="headerlink" href="#how-do-you-communicate-ml-predictions-and-does-it-matter" title="Permalink to this heading">#</a></h2>
<p>In <span class="xref myst"><em>An explainable deep-learning algorithm for the detection of acute intracranial haemorrhage from small datasets</em></span> (Lee et al, Nature Biomedical Engineering, 2019), the authors build a neural network model to detect acute intracranial haemorrhage (ICH) and classifies five ICH subtypes.</p>
<p>Model classifications are explained by highlighting the pixels that contributed the most to the decision. The highligthed regions tends to overlapped with ‘bleeding points’ annotated by neuroradiologists on the images.</p>
<img src="./fig/shap.png" style="height: 350px;" align="center"/></section>
<section id="what-interactions-do-we-need-to-think-about-when-we-design-ml-models">
<h2>What Interactions Do We Need to Think About When We Design ML Models?<a class="headerlink" href="#what-interactions-do-we-need-to-think-about-when-we-design-ml-models" title="Permalink to this heading">#</a></h2>
<p>We tend to think of modeling as a purely mathematical or engineering feat, but in many cases the model has a complex interaction with a human decision maker.</p>
<p>We also tend to think of the tech and the user as a closed system. but your tech is actually one cog in a complex <strong>social-technical system</strong>, your intended use is just one actor in a web of stakeholders.</p>
<p>We not only need to worry about the performance of the model, we also need to worry about the performance the combined system of Human + AI.</p>
<img src="fig/slide13.png" style="height:350px;" align="center"/></section>
<section id="the-promises-of-human-ai-systems">
<h2>The Promises of Human + AI Systems<a class="headerlink" href="#the-promises-of-human-ai-systems" title="Permalink to this heading">#</a></h2>
<p>In <span class="xref myst"><em>Consistent Estimators for Learning to Defer to an Expert</em></span> (Mozannar et al, International Conference on Machine Learning, 2020), the authors trains a model that decides when (and how) to classify an input and when to defer the decision to an human expert.</p>
<p>The joint Human + AI system can be superior to both components.</p>
<img src="./fig/human+ai2.png" style="height: 400px;" align="center"/></section>
<section id="the-perils-of-human-ai-systems">
<h2>The Perils of Human + AI Systems<a class="headerlink" href="#the-perils-of-human-ai-systems" title="Permalink to this heading">#</a></h2>
<p>In <span class="xref myst"><em>How machine-learning recommendations influence clinician treatment selections: the example of antidepressant selection</em></span> (Jacobs et al, Translational Psychiatry, 2021), the authors found that clinicians interacting with incorrect recommendations paired with simple explanations experienced significant reduction in treatment selection accuracy.</p>
<img src="./fig/reliance.png" style="height: 400px;" align="center"/>
<p>Incorrect ML recommendations may adversely impact clinician treatment selections and that explanations are insufficient for addressing overreliance on imperfect ML algorithms.</p>
</section>
<section id="the-potential-social-benifits-of-machine-learning">
<h2>The Potential Social Benifits of Machine Learning<a class="headerlink" href="#the-potential-social-benifits-of-machine-learning" title="Permalink to this heading">#</a></h2>
<p><em><strong>Artifcial intellegence</strong></em> or <em><strong>machine learning</strong></em> models are becoming increasinglly ubiquitous in modern life. These models have already made meaningful impact on many of the most pressing problems we face today.</p>
<img src="./fig/benifits.jpeg" style="height: 500px;" align="center"/>
</section>
<section id="the-negative-social-impacts-of-machine-learning">
<h2>The Negative Social Impacts of Machine Learning<a class="headerlink" href="#the-negative-social-impacts-of-machine-learning" title="Permalink to this heading">#</a></h2>
<img src="./fig/risks.jpeg" style="height: 500px;" align="center"/>
</section>
<section id="why-is-this-happening">
<h2>Why Is This Happening?<a class="headerlink" href="#why-is-this-happening" title="Permalink to this heading">#</a></h2>
<p>Bias in tech is not an algorithmic or math problem; it is a people problem, it is about neglecting the human dimension and inextricably linked with diversity &amp; representation in the ways we approach problem solving.</p>
<img src="./fig/gaps.jpeg" style="height: 500px;" align="center"/></section>
<section id="alternative-problem-solving-frameworks-for-machine-learning">
<h2>Alternative Problem Solving Frameworks for Machine Learning<a class="headerlink" href="#alternative-problem-solving-frameworks-for-machine-learning" title="Permalink to this heading">#</a></h2>
<p>Machine learning is making a movement away from traditional design frameworks and problem solving methodologies.</p>
<img src="./fig/participate.jpeg" style="height: 500px;" align="center"/></section>
<section id="machine-learning-much-more-than-accuracy">
<h2>Machine Learning: Much More Than Accuracy<a class="headerlink" href="#machine-learning-much-more-than-accuracy" title="Permalink to this heading">#</a></h2>
<p>Machine learning is much more than engineering for abstract performance metrics. Increasingly the field is grappling with the role digital technology is playing in our entire socio-technical system.</p>
<p>Machine learning and data science are <strong>interdisciplinary</strong> fields that require people with <strong>diverse skill-sets/backgrounds</strong> to work closely and <strong>cooperatively</strong>.</p>
<p>There is also increasing calls for machine learning/data science researchers to engage meaningfully with <strong>social, economic, political, cultural and ethical impacts</strong> of their work when embedded in complex human institutions.</p>
<img src="fig/slide19.png" style="height:350px;" align="center"/></section>
<section id="what-is-am207">
<h2>What is AM207?<a class="headerlink" href="#what-is-am207" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Build statistical (Bayesian and non-Bayesian) models for: continuous, ordinal and categorical data</p></li>
<li><p>Study algorithms for model fitting and inference</p></li>
<li><p>Study paradigms for model evaluation and critique</p></li>
<li><p>Understand ways models can fail or produce unintended negative impact in real-life settings</p></li>
</ol>
<p><strong>Goal:</strong> students become familiar with standard statistical models and modern techniques of inference. At the end of the course you should be able to productively read current machine learning research papers and apply these models to solve real-life problems. You should also be able to anticipate model failure modes and perform nuanced analyses of the broader social impact of your model.</p>
<p><strong>Focus:</strong></p>
<ul class="simple">
<li><p><strong>Why:</strong> theory should serve a concrete purpose.</p></li>
<li><p><strong>How:</strong> emphasize computational aspects of inference.</p></li>
<li><p><strong>But Should I?:</strong> anticipate failure modes and negative social impacts.</p></li>
</ul>
<p><strong>Related Courses:</strong> Bayesian Inference (Stats), Advanced Machine Learning (CS), Computational Statistics (Stats)</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="what-technologies-do-you-need-for-this-class">
<h1><span class="section-number">3. </span>What technologies do you need for this class?<a class="headerlink" href="#what-technologies-do-you-need-for-this-class" title="Permalink to this heading">#</a></h1>
<section id="for-meetings">
<h2>For Meetings<a class="headerlink" href="#for-meetings" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>We will meet in person for classes and office hours. Students who cannot attend in-person meetings can obtain an exception from the instructor and attend classes and office hours via over <a class="reference external" href="https://zoom.us">Zoom</a>.</p></li>
<li><p>Students can work together virtually in the <a class="reference external" href="https://gather.town">gather.town</a> room created for this course.</p></li>
</ul>
</section>
<section id="gather-town-s-virtual-environment">
<h2><code class="docutils literal notranslate"><span class="pre">gather.town</span></code>’s Virtual Environment<a class="headerlink" href="#gather-town-s-virtual-environment" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">HTML</span><span class="p">(</span><span class="s1">&#39;&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/dqG6-ehe39w?rel=0&amp;amp;controls=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/IPython/core/display.py:431: UserWarning: Consider using IPython.display.IFrame instead
  warnings.warn(&quot;Consider using IPython.display.IFrame instead&quot;)
</pre></div>
</div>
<div class="output text_html"><iframe width="560" height="315" src="https://www.youtube.com/embed/dqG6-ehe39w?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allowfullscreen></iframe></div></div>
</div>
</section>
<section id="for-completing-assignments">
<h2>For Completing Assignments<a class="headerlink" href="#for-completing-assignments" title="Permalink to this heading">#</a></h2>
<p>Homework will be completed in Jupyter Notebooks.</p>
<p>You have one of two options</p>
<ol class="arabic simple">
<li><p>Download the latest <a class="reference external" href="https://www.anaconda.com/products/individual">Anaconda <code class="docutils literal notranslate"><span class="pre">python</span></code> 3.x</a> distribution on your personal machine</p></li>
<li><p>Complete homework using <a class="reference external" href="https://deepnote.com/">Deepnote</a> - a free cloud computing service that comes with pre-installed machine learning tools. Deepnote is built on Jupyter Notebooks, an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text.</p></li>
</ol>
</section>
<section id="for-in-class-exercises">
<h2>For In-Class Exercises<a class="headerlink" href="#for-in-class-exercises" title="Permalink to this heading">#</a></h2>
<p>In class exercises are completed in <a class="reference external" href="https://deepnote.com/">Deepnote</a>. Duplicate the starter code to your personal workspace. Turn on “Sharing” for your notebook (so that anyone with the link can view) and submit the share link to the Course Canvas.</p>
<p>Each group submits a single notebook.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="how-is-this-course-structured">
<h1><span class="section-number">4. </span>How is this course structured?<a class="headerlink" href="#how-is-this-course-structured" title="Permalink to this heading">#</a></h1>
<section id="graded-components">
<h2>Graded Components<a class="headerlink" href="#graded-components" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Concept quizzes following lecture videos</p></li>
<li><p>In-class group exercises</p></li>
<li><p>9 equally weighted weekly homework</p></li>
<li><p>1 group project</p></li>
</ol>
<p>Each homework will be a combination of derivations/proofs (theory) and programming (implementation).</p>
<p>The group project involves choosing one pre-approved research paper and producing a tutorial in Jupyter Notebook to demonstrate the concepts and methodologies in the paper.</p>
</section>
<section id="policies">
<h2>Policies<a class="headerlink" href="#policies" title="Permalink to this heading">#</a></h2>
<p><strong>Grading:</strong> Unreadable formatting or code with syntactic or runtime errrors will not be graded. “Right” answer without a (brief) justification will not receive full score. You can drop your lowest HW grade.</p>
<p><strong>Late HW:</strong> Each student has <strong>three</strong> late days that can be applied to any one or two homework. Outside of late days, late submissions will not be accepted.</p>
<p><strong>Collaboration:</strong> Collaboration is strongly encouraged, but copying is strictly not allowed (see policy on Syllabus).</p>
<p><strong>Attendance:</strong> Attendance of class meetings is required. Attendance waivers can be obtained by contacting the instructor.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="how-do-i-get-help-for-the-course">
<h1><span class="section-number">5. </span>How do I get help for the course?<a class="headerlink" href="#how-do-i-get-help-for-the-course" title="Permalink to this heading">#</a></h1>
<section id="teaching-staff">
<h2>Teaching Staff<a class="headerlink" href="#teaching-staff" title="Permalink to this heading">#</a></h2>
<p><strong>Instructor:</strong> Weiwei Pan</p>
<p><strong>TFs:</strong></p>
<ul class="simple">
<li><p>Haoxue Fan</p></li>
<li><p>Max Cembalest</p></li>
<li><p>Elaine Cunha</p></li>
<li><p>Felipe Gomez</p></li>
<li><p>David Asseraf</p></li>
<li><p>Sean Gao</p></li>
<li><p>Claire Tseng</p></li>
<li><p>David Ma</p></li>
<li><p>Jiayu Yao</p></li>
</ul>
</section>
<section id="tf-office-hours">
<h2>TF Office Hours<a class="headerlink" href="#tf-office-hours" title="Permalink to this heading">#</a></h2>
<p>Students need to submit their questions as comments on the appropriate Piazza post <em><strong>prior to each TF office hour</strong></em>. During each OH, similar questions will be consolidated and answered in the order they were submitted.</p>
<p>Each OH has a specific focus, questions that are not aligned with the focus of the session will be given lower priority. For example, on Monday, questions about how to get started on homework problems will be prioritized lower than trouble-shooting questions on solutions in progress.</p>
<ul class="simple">
<li><p><strong>(Saturday)</strong> Focus: background concepts and homework problem setup</p></li>
<li><p><strong>(Sunday)</strong> Focus: background concepts and homework problem setup</p></li>
<li><p><strong>(Monday)</strong> Focus: implementation and trouble shooting</p></li>
<li><p><strong>(Tuesday)</strong> Focus: implementation and trouble shooting</p></li>
<li><p><strong>(Wednesday)</strong> Focus: interpretation</p></li>
</ul>
</section>
<section id="instructor-office-hours">
<h2>Instructor Office Hours<a class="headerlink" href="#instructor-office-hours" title="Permalink to this heading">#</a></h2>
<p>The focus of TF office hours is on providing support for homework assignments. The focus on instructor office hours is to support general understanding of the class material.</p>
<p>While you are welcome to bring questions about homework assignments to instructor office hours, you may get more out of your total face-time with staff if you can make use of both sets of office hours.</p>
<p>Suggested workflow:</p>
<ul class="simple">
<li><p><strong>(Friday)</strong> clarify concepts covered during the week during instructor office hour</p></li>
<li><p><strong>(Saturday and/or Sunday)</strong> setup all homework problems during TF office hours</p></li>
<li><p><strong>(Monday and/or Tuesday)</strong> trouble-shoot implementation issues during TF office hours</p></li>
<li><p><strong>(Wednsday)</strong> discuss interpretation during instructor office hour</p></li>
</ul>
</section>
<section id="piazza">
<h2>Piazza<a class="headerlink" href="#piazza" title="Permalink to this heading">#</a></h2>
<p>There is a course Piazza to faciliate collaboration amongst students.</p>
<p>Teaching staff moderate the discussions but are <strong>not responsible for answering questions</strong>!</p>
<p>If you want help from the staff come to an office hour or schedule a meeting.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="final-words-of-advice">
<h1><span class="section-number">6. </span>Final Words of Advice<a class="headerlink" href="#final-words-of-advice" title="Permalink to this heading">#</a></h1>
<section id="how-we-ve-changed-am207">
<h2>How We’ve Changed AM207<a class="headerlink" href="#how-we-ve-changed-am207" title="Permalink to this heading">#</a></h2>
<p>Last year, when we learned that AM207 will be remote, we made a number of fundamental changes to maximize the time you have to interact with each other and staff. Because these changes were universally approved by students, we have kept these changes for 2021:</p>
<ol class="arabic simple">
<li><p>We’ve doubled the sections to keep enorllment in each section small</p></li>
<li><p>We’ve doubled OHs</p></li>
<li><p>We’ve flipped the classroom, so that class time is interactive and active</p></li>
</ol>
</section>
<section id="what-we-are-asking-from-you">
<h2>What We are Asking From You<a class="headerlink" href="#what-we-are-asking-from-you" title="Permalink to this heading">#</a></h2>
<p>We are asking you also put in work in order to make this a successful learning experience:</p>
<ol class="arabic simple">
<li><p>Come to office hours</p></li>
<li><p>Ask questions:</p></li>
</ol>
<ul class="simple">
<li><p><strong>Ask questions to understand</strong>. There is no such thing as an obvious fact or a trivial question. Don’t let shyness of intimidation prevent you from asking for help to understand something.</p></li>
<li><p><strong>Ask questions to dig deeper</strong>. Every single concept in this course serves a purpose and has a justification. Don’t settle for knowing facts, there’s always a questions you can ask about something you already know that will show you something new and something deep.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Focus on creating connections, relation between and syntheses of concept. Don’t worry about memorizing lines of math.</p></li>
</ol>
</section>
<section id="how-to-work-in-teams">
<h2>How to Work in Teams<a class="headerlink" href="#how-to-work-in-teams" title="Permalink to this heading">#</a></h2>
<p>Most of the work you do in AM207 you will do in teams. Since this is a traditionally diverse class in terms of backgrounds, your teammates will likely not have the same outlook and expertise as you.</p>
<ol class="arabic simple">
<li><p><strong>When you’re the one in the know</strong> If you find a section of the material easy, don’t settle for just doing the work for your team! Your challenge in this case is to teach, find a way to bring your teammates to your level of understanding.</p></li>
<li><p><strong>When you’re the one in the dark</strong> If you find yourself lost on a task and someone else seems to be taking the lead, don’t settle into the “back-seat”! Your challenge in this case is to ask good critical questions and interrogate the validity of every “answer” being proposed.</p></li>
<li><p><strong>When you disagree</strong> Solicit everyone’s opinion, take time to understand what they are saying, be open to discussions (be able to suspend your own skepticism). When you can’t reconcile difference, come to us and we can continue the discussion.</p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Probabilistic Foundations of Machine Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="lecture_2_notes.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7. </span>Lecture #2: Maximimum Likelihood Estimation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">1. Lecture #1: Course Overview</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#outline">Outline</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-this-course-about">2. What is this course about?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-model-patterns-in-data">How Do We Model Patterns in Data?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">How Do We Model Patterns in Data?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-model">What is a Model?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">What is a Model?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-notion-of-error">A Notion of Error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-quantify-the-overall-error">How do we quantify the overall error?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-fitting">Model Fitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-in-sklearn">Linear Regression in <code class="docutils literal notranslate"><span class="pre">sklearn</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-statistical-model">What is a Statistical Model?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-statistical-model-for-regression">A Statistical Model for Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-quantify-fitness">How Do We Quantify Fitness?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Model Fitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximimum-likelihood-and-minimum-mean-square-error">Maximimum Likelihood and Minimum Mean Square Error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-evaluation">Model Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-interpretation">Model Interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-bayesian-model">What is a Bayesian Model?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-inference">Model Inference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-linear-regression">Bayesian Linear Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-versus-frequentist-uncertainty">Bayesian versus Frequentist Uncertainty</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Model Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-is-this-hard">Why is This Hard?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#is-accuracy-enough">Is Accuracy Enough?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-kinds-of-predictive-uncertainty-do-we-want">What Kinds of Predictive Uncertainty Do We Want?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">What Kinds of Predictive Uncertainty Do We Want?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#so-now-you-have-predictive-uncertainties-what-are-you-gonna-do-with-them">So Now You Have Predictive Uncertainties, What Are You Gonna Do With Them?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-explain-decisions-of-machine-learning-models">How Do We Explain Decisions of Machine Learning Models?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-you-communicate-ml-predictions-and-does-it-matter">How Do You Communicate ML Predictions, And Does It Matter?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-interactions-do-we-need-to-think-about-when-we-design-ml-models">What Interactions Do We Need to Think About When We Design ML Models?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-promises-of-human-ai-systems">The Promises of Human + AI Systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-perils-of-human-ai-systems">The Perils of Human + AI Systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-potential-social-benifits-of-machine-learning">The Potential Social Benifits of Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-negative-social-impacts-of-machine-learning">The Negative Social Impacts of Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-is-this-happening">Why Is This Happening?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alternative-problem-solving-frameworks-for-machine-learning">Alternative Problem Solving Frameworks for Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-much-more-than-accuracy">Machine Learning: Much More Than Accuracy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-am207">What is AM207?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#what-technologies-do-you-need-for-this-class">3. What technologies do you need for this class?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-meetings">For Meetings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gather-town-s-virtual-environment"><code class="docutils literal notranslate"><span class="pre">gather.town</span></code>’s Virtual Environment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-completing-assignments">For Completing Assignments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-in-class-exercises">For In-Class Exercises</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#how-is-this-course-structured">4. How is this course structured?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graded-components">Graded Components</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#policies">Policies</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-i-get-help-for-the-course">5. How do I get help for the course?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teaching-staff">Teaching Staff</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tf-office-hours">TF Office Hours</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instructor-office-hours">Instructor Office Hours</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#piazza">Piazza</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#final-words-of-advice">6. Final Words of Advice</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-we-ve-changed-am207">How We’ve Changed AM207</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-we-are-asking-from-you">What We are Asking From You</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-work-in-teams">How to Work in Teams</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yaniv Yacoby
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>