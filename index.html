

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Probabilistic Foundations of Machine Learning &#8212; Probabilistic Foundations of Machine Learning (CS349)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'index';</script>
    <link rel="canonical" href="https://mogu-lab.github.io/cs349-fall-2024/index.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="1. Lecture #1: Course Overview" href="lectures/lecture_1_notes.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="#">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1 current active">
                <a class="reference internal" href="#">
                    Probabilistic Foundations of Machine Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Exact Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_1_notes.html">1. Lecture #1: Course Overview</a></li>





<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_2_notes.html">7. Lecture #2: Maximimum Likelihood Estimation</a></li>






<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_3_notes.html">14. Lecture #3: Bayesian Modeling</a></li>






<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_4_notes.html">21. Lecture #4: Bayesian versus Frequentist Inference</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Sampling-Based Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_5_notes.html">1. Lecture #5: Sampling for Posterior Simulation</a></li>





<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_6_notes.html">7. Lecture #6: Monte Carlo Integration</a></li>






<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_7_notes.html">14. Lecture #7: Markov Chain Monte Carlo</a></li>



<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_8_notes.html">18. Lecture #8: Metropolis-Hastings and Gibbs</a></li>




<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_9_notes.html">23. Lecture #9: Latent Variable Models and MLE</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Gradient-Based Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_10_notes.html">1. Lecture #10: Bayesian Latent Variable Models and Variational Inference</a></li>

<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_11_notes.html">3. Lecture #11: Hierarchical Models</a></li>



<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_12_notes.html">7. Lecture #12: Logistic Regression and Gradient Descent</a></li>



<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_13_notes.html">11. Lecture #13: Stochastic Gradient Descent and Simulated Annealing</a></li>





<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_14_notes.html">17. Lecture #14: Hamiltonian Monte Carlo</a></li>



<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_15_notes.html">21. Lecture #15: Parallel Tempering and Stochastic HMC</a></li>



<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_16_notes.html">25. Lecture #16: Neural Network Models for Regression</a></li>





<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_17_notes.html">31. Lecture #17: Black-box Variational Inference</a></li>



<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_18_notes.html">35. Lecture #18: Automatic Differentiation</a></li>


<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_19_notes.html">38. Lecture #19: Variational Inference in Context</a></li>




<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_20_notes.html">43. Lecture #20: Variational Autoencoders</a></li>


<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_21_notes.html">46. Lecture #21: Implementation of Variational Autoencoders</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/index.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probabilistic Foundations of Machine Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#syllabus">Syllabus</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#schedule">Schedule</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-notes">Lecture Notes</a><ul class="nav section-nav flex-column">
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probabilistic-foundations-of-machine-learning">
<h1>Probabilistic Foundations of Machine Learning<a class="headerlink" href="#probabilistic-foundations-of-machine-learning" title="Permalink to this heading">#</a></h1>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This book is currently under construction!</p>
</div>
<p><strong>Instructor:</strong> <a class="reference external" href="https://yanivyacoby.github.io/">Yaniv Yacoby</a></p>
<p><strong>Semester:</strong> Fall 2024</p>
<p><strong>Course Number:</strong> CS 349</p>
<p><strong>Description:</strong> In recent years, Artificial Intelligence has enabled applications that were previously not thought possible—from systems that propose novel drugs or generate new art/music, to systems that accurately and reliably predict outcomes of medical interventions in real-time. But what has enabled these developments? Probabilistic Machine Learning, a paradigm that casts recent advances in Machine Learning, like neural networks, into a statistical learning framework. In this course, we introduce the foundational concepts behind this paradigm—statistical model specification, and statistical learning and inference—focusing on connecting theory with real-world applications and hands-on practice. This course lays the foundation for advanced study and research in Machine Learning. Topics include: directed graphical models, deep Bayesian regression/classification, generative models (latent variable models) for clustering, dimensionality reduction, and time-series forecasting. Students will get hands-on experience building models for specific tasks, most taken from healthcare contexts, using a probabilistic programming language based in Python.</p>
<section id="syllabus">
<h2>Syllabus<a class="headerlink" href="#syllabus" title="Permalink to this heading">#</a></h2>
<p>TODO</p>
</section>
<section id="schedule">
<h2>Schedule<a class="headerlink" href="#schedule" title="Permalink to this heading">#</a></h2>
<p>TODO</p>
</section>
<section id="lecture-notes">
<h2>Lecture Notes<a class="headerlink" href="#lecture-notes" title="Permalink to this heading">#</a></h2>
<div class="toctree-wrapper compound">
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Exact Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_1_notes.html">1. Lecture #1: Course Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_1_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_1_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_1_notes.html#what-is-this-course-about">2. What is this course about?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#how-do-we-model-patterns-in-data">How Do We Model Patterns in Data?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#id1">How Do We Model Patterns in Data?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#what-is-a-model">What is a Model?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#id2">What is a Model?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#a-notion-of-error">A Notion of Error</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#how-do-we-quantify-the-overall-error">How do we quantify the overall error?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#model-fitting">Model Fitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#linear-regression-in-sklearn">Linear Regression in <code class="docutils literal notranslate"><span class="pre">sklearn</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#what-is-a-statistical-model">What is a Statistical Model?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#a-statistical-model-for-regression">A Statistical Model for Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#how-do-we-quantify-fitness">How Do We Quantify Fitness?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#id3">Model Fitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#maximimum-likelihood-and-minimum-mean-square-error">Maximimum Likelihood and Minimum Mean Square Error</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#model-evaluation">Model Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#model-interpretation">Model Interpretation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#what-is-a-bayesian-model">What is a Bayesian Model?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#model-inference">Model Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#bayesian-linear-regression">Bayesian Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#bayesian-versus-frequentist-uncertainty">Bayesian versus Frequentist Uncertainty</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#id4">Model Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#why-is-this-hard">Why is This Hard?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#is-accuracy-enough">Is Accuracy Enough?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#what-kinds-of-predictive-uncertainty-do-we-want">What Kinds of Predictive Uncertainty Do We Want?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#id5">What Kinds of Predictive Uncertainty Do We Want?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#so-now-you-have-predictive-uncertainties-what-are-you-gonna-do-with-them">So Now You Have Predictive Uncertainties, What Are You Gonna Do With Them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#how-do-we-explain-decisions-of-machine-learning-models">How Do We Explain Decisions of Machine Learning Models?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#how-do-you-communicate-ml-predictions-and-does-it-matter">How Do You Communicate ML Predictions, And Does It Matter?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#what-interactions-do-we-need-to-think-about-when-we-design-ml-models">What Interactions Do We Need to Think About When We Design ML Models?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#the-promises-of-human-ai-systems">The Promises of Human + AI Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#the-perils-of-human-ai-systems">The Perils of Human + AI Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#the-potential-social-benifits-of-machine-learning">The Potential Social Benifits of Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#the-negative-social-impacts-of-machine-learning">The Negative Social Impacts of Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#why-is-this-happening">Why Is This Happening?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#alternative-problem-solving-frameworks-for-machine-learning">Alternative Problem Solving Frameworks for Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#machine-learning-much-more-than-accuracy">Machine Learning: Much More Than Accuracy</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#what-is-am207">What is AM207?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_1_notes.html#what-technologies-do-you-need-for-this-class">3. What technologies do you need for this class?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#for-meetings">For Meetings</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#gather-town-s-virtual-environment"><code class="docutils literal notranslate"><span class="pre">gather.town</span></code>’s Virtual Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#for-completing-assignments">For Completing Assignments</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#for-in-class-exercises">For In-Class Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_1_notes.html#how-is-this-course-structured">4. How is this course structured?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#graded-components">Graded Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#policies">Policies</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_1_notes.html#how-do-i-get-help-for-the-course">5. How do I get help for the course?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#teaching-staff">Teaching Staff</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#tf-office-hours">TF Office Hours</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#instructor-office-hours">Instructor Office Hours</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#piazza">Piazza</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_1_notes.html#final-words-of-advice">6. Final Words of Advice</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#how-we-ve-changed-am207">How We’ve Changed AM207</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#what-we-are-asking-from-you">What We are Asking From You</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_1_notes.html#how-to-work-in-teams">How to Work in Teams</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_2_notes.html">7. Lecture #2: Maximimum Likelihood Estimation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_2_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_2_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_2_notes.html#a-motivating-example">8. A Motivating Example</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#a-simple-betting-game">A Simple Betting Game</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#estimating-the-bias-of-a-coin">Estimating the “Bias” of a Coin</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_2_notes.html#a-statistical-model-for-a-coin-toss">9. A Statistical Model for a Coin Toss</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#likelihood-for-a-coin-toss">Likelihood for a Coin Toss</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_2_notes.html#maximum-likelihood-estimation">10. Maximum Likelihood Estimation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#parameter-estimation-maximum-likelihood">Parameter Estimation: Maximum Likelihood</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#maximizing-likelihood-is-equivalent-to-maximizing-log-likelihood">Maximizing Likelihood is Equivalent to Maximizing Log-Likelihood</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_2_notes.html#convex-optimization-constrained-and-unconstrained">11. Convex Optimization: Constrained and Unconstrained</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#introduction-to-optimization-types-of-optima">Introduction to Optimization: Types of Optima</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#stationary-points">Stationary Points</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#characterization-of-local-optima">Characterization of Local Optima</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#characterization-of-global-optima">Characterization of Global Optima</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#unconstrained-optimization">Unconstrained Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#example-poisson-distribution">Example: Poisson Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#example-univariate-gaussian-distribution">Example: (Univariate) Gaussian Distribution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_2_notes.html#likelihood-and-log-likelihood">Likelihood and log-likelihood</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#id1">Example: (Univariate) Gaussian Distribution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_2_notes.html#gradient-of-log-likelihood">Gradient of log-likelihood</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#id2">Example: (Univariate) Gaussian Distribution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_2_notes.html#stationary-points-of-the-gradient">Stationary points of the gradient</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#id3">Example: (Univariate) Gaussian Distribution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_2_notes.html#characterize-local-and-global-optima">Characterize local and global optima</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#example-multivariate-gaussian-distribution">Example: (Multivariate) Gaussian Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#constrained-optimization">Constrained Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#constrained-optimization-via-lagrange-multipliers">Constrained Optimization via Lagrange Multipliers</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#example-binomial-distribution">Example: Binomial Distribution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_2_notes.html#id4">Likelihood and Log-Likelihood</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#id5">Example: Binomial Distribution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_2_notes.html#id6">Gradient of log-likelihood</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#id7">Example: Binomial Distribution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_2_notes.html#stationary-points-of-the-lagrangian">Stationary points of the Lagrangian</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#id8">Example: Binomial Distribution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_2_notes.html#characterize-global-optima">Characterize global optima</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#what-is-a-good-estimator">What Is a Good Estimator?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_2_notes.html#properties-of-mle">12. Properties of MLE</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#desiderata-of-estimators">Desiderata of Estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#id9">Desiderata of Estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#id10">Desiderata of Estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#id11">Properties of MLE</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#example-the-mle-can-be-biased">Example: The MLE Can Be Biased</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_2_notes.html#uncertainty-quantification">13. Uncertainty Quantification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#confidence-intervals">Confidence Intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#interpretation-of-confidence-intervals">Interpretation of Confidence Intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_2_notes.html#bootstrap-confidence-intervals">Bootstrap Confidence Intervals</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_3_notes.html">14. Lecture #3: Bayesian Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_3_notes.html#am-207-advanced-scientific-computing">15. AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_3_notes.html#outline">16. Outline</a></li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_3_notes.html#review-of-the-method-of-maximum-likelihood">17. Review of the Method of Maximum Likelihood</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#the-method-of-maximum-likelihood">The Method of Maximum Likelihood</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#evaluating-the-mle">Evaluating the MLE</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#properties-of-the-maximum-likelihood-estimator">Properties of The Maximum Likelihood Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#is-bias-always-bad">Is Bias Always Bad?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_3_notes.html#decomposition-of-mse">Decomposition of MSE</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_3_notes.html#example-of-the-bias-variance-trade-off">Example of the Bias Variance Trade-off</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#limitations-of-mle-overfitting-under-scarcity-of-data">Limitations of MLE: Overfitting Under Scarcity of Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#id1">Limitations of MLE: Overfitting Under Scarcity of Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#regularization">Regularization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_3_notes.html#models-for-real-data">18. Models for Real Data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#die-roll">Die Roll</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#video-ranking">Video Ranking</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#kidney-cancer-rates">Kidney Cancer Rates</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#id2">Kidney Cancer Rates</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#birth-weights">Birth Weights</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_3_notes.html#the-beta-binomial-model">19. The Beta-Binomial Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#the-coin-toss-model-revisited">The Coin Toss Model: Revisited</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#incoporating-prior-beliefs">Incoporating Prior Beliefs</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#id3">The Beta-Binomial Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#posterior-for-the-beta-binomial-model">Posterior for the Beta-Binomial Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#interpreting-the-posterior-bayesian-update">Interpreting the Posterior: Bayesian Update</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#simulation-bayesian-update-for-the-coin-flip">Simulation: Bayesian Update for the Coin Flip</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#simulation-iterated-bayesian-update-for-the-coin-flip">Simulation: Iterated Bayesian Update for the Coin Flip</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#making-predictions">Making Predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#simulation-posterior-predictive-for-the-coin-flip">Simulation: Posterior Predictive for the Coin Flip</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_3_notes.html#bayesian-modeling-a-summary">20. Bayesian Modeling - A Summary</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#the-bayesian-modeling-process">The Bayesian Modeling Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#evaluating-bayesian-models">Evaluating Bayesian Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#where-do-priors-come-from">Where do Priors Come From?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_3_notes.html#uninformative-priors-how-to-say-i-don-t-know">Uninformative Priors: How to Say I Don’t Know</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_4_notes.html">21. Lecture #4: Bayesian versus Frequentist Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_4_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_4_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_4_notes.html#review-of-bayesian-modeling">22. Review of Bayesian Modeling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#the-bayesian-modeling-process">The Bayesian Modeling Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#bayesian-update">Bayesian Update</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#model-evaluation">Model Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#components-of-bayesian-inference">Components of Bayesian Inference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_4_notes.html#examples-of-conjugate-and-non-conjugate-models">23. Examples of Conjugate and Non-Conjugate Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#bayesian-model-for-univariate-gaussian-likelihood-with-known-variance">Bayesian Model for (Univariate) Gaussian Likelihood with Known Variance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_4_notes.html#the-bayesian-model">The Bayesian Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#id1">Bayesian Model for (Univariate) Gaussian Likelihood with Known Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#bayesian-model-for-univariate-gaussian-likelihood-with-known-mean">Bayesian Model for (Univariate) Gaussian Likelihood with Known Mean</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_4_notes.html#id2">The Bayesian Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#id3">Bayesian Model for (Univariate) Gaussian Likelihood with Known Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#bayesian-model-for-univariate-gaussian-likelihood-with-unknown-mean-and-variance">Bayesian Model for (Univariate) Gaussian Likelihood with Unknown Mean and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#bayesian-model-for-poisson-likelihood">Bayesian Model for Poisson Likelihood</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_4_notes.html#id4">The Bayesian Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_4_notes.html#inference">Inference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#non-conjugate-models">Non-Conjugate Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_4_notes.html#connections-with-frequentist-inference">24. Connections with Frequentist Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#point-estimates-from-the-posterior">Point Estimates from the Posterior</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#point-estimates-can-be-misleading">Point Estimates Can Be Misleading</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#id5">Point Estimates Can Be Misleading</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#comparison-of-posterior-point-estimates-and-mle">Comparison of Posterior Point Estimates and MLE</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#the-coin-toss-example-revisited-yet-again">The Coin Toss Example: Revisited Yet Again</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#law-of-large-numbers-for-bayesian-inference">Law of Large Numbers for Bayesian Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_4_notes.html#computational-comparisons">Computational Comparisons</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Sampling-Based Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_5_notes.html">1. Lecture #5: Sampling for Posterior Simulation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_5_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_5_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_5_notes.html#basics-of-sampling">2. Basics of Sampling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#motivation">Motivation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#what-is-sampling">What is Sampling?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#simulating-a-uniform-random-variable-linear-congruence">Simulating a Uniform Random Variable: Linear Congruence</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_5_notes.html#inverse-cdf-sampling">3. Inverse CDF Sampling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#the-cumulative-distribution-function">The Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#inverse-cdf-sampling-an-intuition">Inverse CDF Sampling: An Intuition</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#id1">Inverse CDF Sampling: An Intuition</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#inverse-cdf-sampling-algorithm">Inverse CDF Sampling: Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#inverse-cdf-sampling-proof-of-correctness">Inverse CDF Sampling: Proof of Correctness</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#simulating-an-exponential-random-variable">Simulating an Exponential Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#id2">Simulating an Exponential Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#simulating-a-bernoulli-random-variable">Simulating a Bernoulli Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#id3">Simulating a Bernoulli Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#what-can-we-simulate">What Can We Simulate?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_5_notes.html#rejection-sampling">4. Rejection Sampling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#rejection-sampling-an-intuition">Rejection Sampling: An Intuition</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#rejection-sampling-algorithm">Rejection Sampling: Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#rejection-sampling-proof-of-correctness">Rejection Sampling: Proof of Correctness</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#rejection-sampling-efficiency">Rejection Sampling: Efficiency</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#simulating-a-normal-random-variable">Simulating a Normal Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#id4">Simulating a Normal Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#id5">What Can We Simulate?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#limitations-of-rejection-sampling-in-high-dimensions">Limitations of Rejection Sampling in High Dimensions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_5_notes.html#gibbs-sampling">5. Gibbs Sampling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#semi-conjugate-priors">Semi-Conjugate Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#gibbs-sampling-an-intuition">Gibbs Sampling: An Intuition</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#gibbs-sampling-algorithm">Gibbs Sampling: Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#simulating-the-posterior-of-a-normal-normal-inverse-gamma-model">Simulating the Posterior of a Normal-Normal-Inverse Gamma Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_5_notes.html#summarizing-sampling">6. Summarizing Sampling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#samplers-for-simulating-random-variables">Samplers for Simulating Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#how-to-evaluate-a-sampler">How to Evaluate a Sampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#why-are-we-sampling-again">Why are We Sampling Again?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_5_notes.html#what-if-we-want-posterior-point-estimates">What If We Want Posterior Point Estimates?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_6_notes.html">7. Lecture #6: Monte Carlo Integration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_6_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_6_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#outline">Outline</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#motivation">Motivation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_6_notes.html#basics-of-monte-carlo-integration">8. Basics of Monte Carlo Integration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#naive-monte-carlo-estimation-of-integrals">Naive Monte Carlo Estimation of Integrals</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#the-consistency-and-unbiasedness-of-monte-carlo-estimators">The Consistency and Unbiasedness of Monte Carlo Estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#the-variance-and-error-of-monte-carlo-estimators">The Variance and Error of Monte Carlo Estimators</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_6_notes.html#variance-reduction-control-variates">9. Variance Reduction: Control Variates</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#a-baseline-for-variance-of-monte-carlo-estimates">A Baseline for Variance of Monte Carlo Estimates</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#the-general-idea-of-control-variates">The General Idea of Control Variates</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#variance-of-control-variates">Variance of Control Variates</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#the-nitty-gritty-of-control-variates">The Nitty Gritty of Control Variates</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#example-control-variates">Example: Control Variates</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#id1">Example: Control Variates</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#id2">Example: Control Variates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_6_notes.html#variance-reduction-stratified-sampling">10. Variance Reduction: Stratified Sampling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#the-general-idea-of-stratified-sampling">The General Idea of Stratified Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#the-stratified-sampling-monte-carlo-estimator">The Stratified Sampling Monte Carlo Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#the-nitty-gritty-of-stratified-sampling-variance-reduction">The Nitty Gritty of Stratified Sampling: Variance Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#example-stratified-sampling">Example: Stratified Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#id3">Example: Stratified Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#id4">Example: Stratified Sampling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_6_notes.html#variance-reduction-importance-sampling">11. Variance Reduction: Importance Sampling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#the-general-idea-of-importance-sampling">The General Idea of Importance Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#variance-of-importance-sampling">Variance of Importance Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#the-nitty-gritty-of-importance-sampling-the-design-of-q">The Nitty Gritty of Importance Sampling: the Design of <span class="math notranslate nohighlight">\(q\)</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#example-importance-sampling">Example: Importance Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#id5">Example: Importance Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#id6">Example: Importance Sampling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_6_notes.html#summary-of-monte-carlo-integration">12. Summary of Monte Carlo Integration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#monte-carlo-integration">Monte Carlo Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#variance-reduction-for-monte-carlo-integration">Variance Reduction for Monte Carlo Integration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_6_notes.html#application-monte-carlo-estimation-of-arbitrary-integrals">13. Application: Monte Carlo Estimation of Arbitrary Integrals</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#arbitrary-definite-integrals">Arbitrary Definite Integrals</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#rewriting-an-arbitrary-definite-integral-as-an-expectation">Rewriting an Arbitrary Definite Integral as an Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_6_notes.html#how-do-you-factor-the-integrand-f">How Do You Factor the Integrand <span class="math notranslate nohighlight">\(f\)</span>?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_7_notes.html">14. Lecture #7: Markov Chain Monte Carlo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_7_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_7_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#outline">Outline</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#motivation">Motivation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_7_notes.html#gibbs-sampler-for-a-discrete-distribution">15. Gibbs Sampler for a Discrete Distribution</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#gibbs-sampler-for-a-bivariate-discrete-distribution">Gibbs Sampler for a Bivariate Discrete Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#gibbs-sampler-as-transition-matrix-and-state-diagram">Gibbs Sampler as Transition Matrix and State Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#limiting-distribution">Limiting Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_7_notes.html#definition-and-properties-of-markov-chains">16. Definition and Properties of Markov Chains</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#markov-chains-in-discrete-and-continuous-spaces">Markov Chains in Discrete and Continuous Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#transition-matrices-and-kernels">Transition Matrices and Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#chapman-kolmogorov-equations-dynamics-as-matrix-multiplication">Chapman-Kolmogorov Equations: Dynamics as Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#example-smart-phone-market-model">Example: Smart Phone Market Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#id1">Example: Smart Phone Market Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#chapman-kolmogorov-equations-continuous-state-space">Chapman-Kolmogorov Equations: Continuous State Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#properties-of-markov-chains-irreducibility">Properties of Markov Chains: Irreducibility</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#properties-of-markov-chains-aperiodicity">Properties of Markov Chains: Aperiodicity</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#properties-of-markov-chains-stationary-distributions">Properties of Markov Chains: Stationary Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#properties-of-markov-chains-limiting-distributions">Properties of Markov Chains: Limiting Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#fundamental-theorm-of-markov-chains">Fundamental Theorm of Markov Chains</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#properties-of-markov-chains-reversibility">Properties of Markov Chains: Reversibility</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#reversibility-and-stationary-distributions">Reversibility and Stationary Distributions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_7_notes.html#markov-chain-monte-carlo">17. Markov Chain Monte Carlo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#markov-chain-monte-carlo-samplers">Markov Chain Monte Carlo Samplers</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#what-do-we-need-to-prove-to-get-pt-p-and-underset-n-to-infty-lim-pi-n-p">What Do We Need to Prove to get <span class="math notranslate nohighlight">\(pT=p\)</span> and <span class="math notranslate nohighlight">\(\underset{n\to \infty}{\lim} \pi^{(n)} = p\)</span>?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_7_notes.html#gibbs-as-mcmc">Gibbs as MCMC</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_8_notes.html">18. Lecture #8: Metropolis-Hastings and Gibbs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_8_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_8_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#outline">Outline</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#motivation">Motivation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_8_notes.html#markov-chain-monte-carlo">19. Markov Chain Monte Carlo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#markov-chain-monte-carlo-samplers">Markov Chain Monte Carlo Samplers</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#what-do-we-need-to-prove-to-get-pt-p-and-underset-n-to-infty-lim-pi-n-p">What Do We Need to Prove to get <span class="math notranslate nohighlight">\(pT=p\)</span> and <span class="math notranslate nohighlight">\(\underset{n\to \infty}{\lim} \pi^{(n)} = p\)</span>?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#metropolis-hastings-the-idea">Metropolis-Hastings: The Idea</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#metropolis-hastings-the-algorithm">Metropolis-Hastings: The Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#metropolis-hastings-proof-of-correctness">Metropolis-Hastings: Proof of Correctness</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#metropolis-hastings-proof-of-detailed-balance">Metropolis-Hastings: Proof of Detailed Balance</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#gibbs-as-metropolis-hastings">Gibbs as Metropolis-Hastings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_8_notes.html#simple-mcmc-diagnostics">20. Simple MCMC Diagnostics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#traceplot-checks-for-mixing">Traceplot Checks for Mixing</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#burn-in-and-thinning">Burn-in and Thinning</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#example-sampling-from-a-mixture-of-two-gaussians">Example: Sampling from a Mixture of Two Gaussians</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#visual-checks-for-mixing">Visual Checks for Mixing</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#visual-checks-can-be-misleading">Visual Checks Can be Misleading</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#the-importance-of-tuning-your-sampler">The Importance of Tuning Your Sampler</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_8_notes.html#more-mcmc-diagnostics-and-best-practices">21. More MCMC Diagnostics and Best Practices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#more-rigorous-checks-for-convergence">More Rigorous Checks for Convergence</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#visual-diagnostics-traceplots-of-multiple-chains">Visual Diagnostics: Traceplots of Multiple Chains</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#autocorrelation-the-effective-sample-size">Autocorrelation: the “Effective” Sample Size</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#visual-diagnostics-the-autocorrelation-plot">Visual Diagnostics: The Autocorrelation Plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#quantitative-diagnostics">Quantitative Diagnostics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_8_notes.html#review-of-statistical-modeling">22. Review of Statistical Modeling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#what-we-can-do-so-far">What We Can Do So Far</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#what-happens-after-inference">What Happens After Inference?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_8_notes.html#the-modeling-process">The Modeling Process</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_9_notes.html">23. Lecture #9: Latent Variable Models and MLE</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_9_notes.html#motivation-for-latent-variable-models">24. Motivation for Latent Variable Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#a-model-for-birth-weights">A Model for Birth Weights</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#a-similarity-measure-for-distributions-kullbackleibler-divergence">A Similarity Measure for Distributions: Kullback–Leibler Divergence</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#why-is-the-kl-bounded-below-by-0">Why is the KL bounded below by 0?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#class-membership-as-a-latent-variable">Class Membership as a Latent Variable</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_9_notes.html#common-latent-variable-models">25. Common Latent Variable Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#latent-variable-models">Latent Variable Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#gaussian-mixture-models-gmms">Gaussian Mixture Models (GMMs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#item-response-models">Item-Response Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#applications">Applications</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#factor-analysis-models">Factor Analysis Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#id1">Applications</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_9_notes.html#maximum-likelihood-estimation-for-latent-variable-models-expectation-maximization">26. Maximum Likelihood Estimation for Latent Variable Models: Expectation Maximization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#expectation-maximization-estimating-the-mle-for-latent-variable-models">Expectation Maximization: Estimating the MLE for Latent Variable Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#step-i-the-m-step">Step I: the M-step</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#step-ii-the-e-step">Step II: the E-step</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#iteration">Iteration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#question-why-don-t-gradients-commute-with-expectation">Question: Why don’t gradients commute with expectation?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#question-why-do-we-need-to-maximize-the-elbo-with-respect-to-q">Question: Why do we need to maximize the ELBO with respect to q?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#the-expectation-maximization-algorithm">The Expectation Maximization Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#the-auxiliary-function">The Auxiliary Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#monotonicity-and-convergence-of-em">Monotonicity and Convergence of EM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#disclaimer">Disclaimer:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#example-em-for-the-gaussian-mixture-model-of-birth-weight">Example: EM for the Gaussian Mixture Model of Birth Weight</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#the-e-step">The E-Step</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#id2">Example: EM for the Gaussian Mixture Model of Birth Weight</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#setting-up-the-m-step">Setting Up the M-Step</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#id3">Example: EM for the Gaussian Mixture Model of Birth Weight</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#solving-the-m-step">Solving the M-Step</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#id4">Example: EM for the Gaussian Mixture Model of Birth Weight</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#all-together">All Together</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#implementing-em-for-the-gaussian-mixture-model-of-birth-weight">Implementing EM for the Gaussian Mixture Model of Birth Weight</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#example-em-for-gaussian-mixture-models-multivariate">Example: EM for Gaussian Mixture Models (Multivariate)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#e-step">E-step:</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#m-step">M-Step:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#sanity-check-log-likelihood-during-training">Sanity Check: Log-Likelihood During Training</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_9_notes.html#review-of-em-for-latent-variable-models">27. Review of EM for Latent Variable Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_9_notes.html#review-latent-variable-models">Review: Latent Variable Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#example-gaussian-mixture-models-gmms">Example: Gaussian Mixture Models (GMMs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_9_notes.html#maximum-likelihood-estimate-inference-for-latent-variable-models">Maximum Likelihood Estimate Inference for Latent Variable Models</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Models and Gradient-Based Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_10_notes.html">1. Lecture #10: Bayesian Latent Variable Models and Variational Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_10_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_10_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_10_notes.html#bayesian-latent-variable-models">2. Bayesian Latent Variable Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#id1">Bayesian Latent Variable Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#challenges-in-bayesian-inference">Challenges in Bayesian Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#the-idea-of-variational-inference">The Idea of Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#the-design-of-the-variational-objective">The Design of the Variational Objective</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#variational-inference-as-optimization">Variational Inference as Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#gradients-of-the-elbo">Gradients of the ELBO</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#coordinate-ascent-variational-inference">Coordinate Ascent Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#maximizing-the-elbo-via-coordinate-ascent">Maximizing the ELBO via Coordinate Ascent</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#proof-of-the-update-rule-for-q-psi-i-lambda-text-new-i">Proof of the Update Rule for <span class="math notranslate nohighlight">\(q(\psi_i | \lambda^{\text{new}}_i)\)</span></a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_10_notes.html#step-1-show-that-mathbb-e-psi-sim-q-psi-lambda-ldots-mathbb-e-psi-i-sim-q-psi-i-lambda-i-left-mathbb-e-psi-i-sim-q-psi-i-lambda-i-ldots-right">Step 1: Show that <span class="math notranslate nohighlight">\(\mathbb{E}_{\psi \sim q(\psi|\lambda)}[\ldots] = \mathbb{E}_{\psi_i \sim q(\psi_i|\lambda_i)}\left[\mathbb{E}_{\psi_{-i} \sim q(\psi_{-i}|\lambda_{-i})}[\ldots] \right]\)</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_10_notes.html#step-2-show-that-underset-lambda-i-max-mathbb-e-psi-i-sim-q-psi-i-lambda-i-ldots-equiv-underset-lambda-i-min-d-text-kl-ldots">Step 2: Show that <span class="math notranslate nohighlight">\(\underset{\lambda_i}{\max}\mathbb{E}_{\psi_i \sim q(\psi_i|\lambda_i)}[\ldots] \equiv \underset{\lambda_i}{\min} D_{\text{KL}}[\ldots]\)</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_10_notes.html#step-3-minimize-the-kl-divergence">Step 3: Minimize the KL-divergence</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#bayesian-gaussian-mixture-models">Bayesian Gaussian Mixture Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#variational-inference-for-bayesian-gaussian-mixture-models">Variational Inference for Bayesian Gaussian Mixture Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#coordinate-ascent-variational-inference-updates-for-bayesian-gmm">Coordinate Ascent Variational Inference Updates for Bayesian GMM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_10_notes.html#update-rule-for-q-z-n-phi-n">Update rule for <span class="math notranslate nohighlight">\(q(Z_n | \phi_n)\)</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_10_notes.html#update-rule-for-q-mu-k-m-k-s-k-2">Update rule for <span class="math notranslate nohighlight">\(q(\mu_k | m_k, s_k^2)\)</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#implemenation-of-cavi-for-bayesian-gmm">Implemenation of CAVI for Bayesian GMM</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_10_notes.html#sanity-check-elbo-during-training">Sanity Check: ELBO During Training</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_11_notes.html">3. Lecture #11: Hierarchical Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_11_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_11_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_11_notes.html#review-of-statistical-modeling">4. Review of Statistical Modeling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#what-we-can-do-so-far-models">What We Can Do So Far: Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#what-we-can-do-so-far-inference">What We Can Do So Far: Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#what-can-we-not-do">What Can We Not Do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#what-happens-after-inference">What Happens After Inference?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#the-modeling-process">The Modeling Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#evaluating-the-predictive-distributions">Evaluating the Predictive Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#interpreting-the-data-log-likelihood">Interpreting the Data Log-Likelihood</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#evaluating-and-quantifying-uncertainty">Evaluating and Quantifying Uncertainty</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_11_notes.html#motivation-for-hierarchical-models">5. Motivation for Hierarchical Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#a-binomial-model-for-movie-rankings">A Binomial Model for Movie Rankings</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#a-beta-binomial-model-for-movie-rankings">A Beta-Binomial Model for Movie Rankings</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#credible-intervals-for-movies-with-the-most-and-the-least-number-of-ratings">Credible Intervals for Movies with the Most and the Least Number of Ratings</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#emprirical-bayes-ml-ii-for-the-beta-binomial-model">Emprirical Bayes (ML-II) For the Beta-Binomial Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#method-of-moments-for-empirical-bayes-ml-ii">Method of Moments for Empirical Bayes (ML-II)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#empirical-bayes-and-shrinkage">Empirical Bayes and Shrinkage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_11_notes.html#hierarchical-models-and-empirical-bayes">6. Hierarchical Models and Empirical Bayes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#a-hierarchical-model-for-movie-rankings">A Hierarchical Model for Movie Rankings</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_11_notes.html#point-estimate-approximations-of-inference-in-hierachical-models-map-ii">Point Estimate Approximations of Inference in Hierachical Models (MAP-II)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_12_notes.html">7. Lecture #12: Logistic Regression and Gradient Descent</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_12_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_12_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_12_notes.html#logistic-regression">8. Logistic Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#coin-toss-revisited-modeling-a-bernoulli-variable-with-covariates">Coin-Toss Revisited: Modeling a Bernoulli Variable with Covariates</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#the-logistic-regression-model">The Logistic Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#the-relationship-between-logistic-regression-and-classification">The Relationship Between Logistic Regression and Classification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_12_notes.html#what-is-classification">What Is Classification?</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_12_notes.html#how-do-we-classify">How Do We Classify?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#interpreting-a-logistic-regression-model">Interpreting a Logistic Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#with-great-explanatory-power-comes-great-responsibility">With Great Explanatory Power Comes Great Responsibility!</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_12_notes.html#when-not-to-use-sensitive-protected-attributes">When not to use sensitive/protected attributes</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_12_notes.html#when-you-might-want-to-use-sensitive-protected-attributes">When you might want to use sensitive/protected attributes</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_12_notes.html#appropriate-usage-of-sensitive-protected-attributes">Appropriate usage of sensitive/protected attributes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#interpreting-a-logistic-regression-model-log-odds">Interpreting a Logistic Regression Model: Log-Odds</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#maximizing-the-logistic-regression-log-likelihood">Maximizing the Logistic Regression Log-likelihood</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_12_notes.html#gradient-descent">9. Gradient Descent</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#gradient-as-directional-information">Gradient as Directional Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#an-intuition-for-gradient-descent">An Intuition for Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#gradient-descent-the-algorithm">Gradient Descent: the Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#diagnosing-design-choices-with-the-trajectory">Diagnosing Design Choices with the Trajectory</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#diagnosing-issues-with-the-trajectory">Diagnosing Issues with the Trajectory</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#id1">Diagnosing Issues with the Trajectory</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#gradient-descent-step-size-matters">Gradient Descent: Step Size Matters</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#gradient-descent-for-logistic-regression">Gradient Descent for Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#but-did-we-optimize-it">But Did We Optimize It?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_12_notes.html#convex-optimization">10. Convex Optimization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#convex-sets">Convex Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#convex-functions">Convex Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#convex-function-first-order-condition">Convex Function: First Order Condition</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#convex-function-second-order-condition">Convex Function: Second Order Condition</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#properties-of-convex-functions">Properties of Convex Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#id2">Convex Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#convexity-of-the-logistic-regression-negative-log-likelihood">Convexity of the Logistic Regression Negative Log-Likelihood</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#but-does-it-always-converge">But Does It Always Converge?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#but-how-quickly-can-we-get-there">But How Quickly Can We Get There?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_12_notes.html#but-does-it-scale">But Does It Scale?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_13_notes.html">11. Lecture #13: Stochastic Gradient Descent and Simulated Annealing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_13_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_13_notes.html#fall-2021">Fall, 2021</a><ul>
<li class="toctree-l4"><a class="reference internal" href="lectures/lecture_13_notes.html#img-src-fig-logos-jpg-style-height-150px"><img src="fig/logos.jpg" style="height:150px;"></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_13_notes.html#generalized-linear-models">12. Generalized Linear Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#a-new-model-logistic-regression">A New Model: Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#id1">Generalized Linear Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_13_notes.html#model-selection-for-hierachical-generalized-linear-models">13. Model Selection for Hierachical Generalized Linear Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#how-many-covariates-to-include">How Many Covariates to Include?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#the-dangers-of-model-interpretation">The Dangers of Model Interpretation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#model-selection-through-cross-validation">Model Selection through Cross-Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#model-selection-for-maximum-likelihood-models">Model Selection for Maximum Likelihood Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#model-selection-via-evidence">Model Selection Via Evidence</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#model-selection-via-bayes-factor">Model Selection Via Bayes Factor</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#model-selection-for-bayesian-models">Model Selection for Bayesian Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_13_notes.html#inference-for-general-linear-models">14. Inference for General Linear Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#general-linear-models">General Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#a-new-inference-algorithm-maximum-likelihood-by-gradient-descent">A New Inference Algorithm: Maximum Likelihood by Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#subtlties-of-gradient-descent-local-vs-global-minima">Subtlties of Gradient Descent: Local vs Global Minima</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#where-does-non-convexity-come-from">Where does Non-Convexity Come From?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#subtlties-of-gradient-descent-scalability">Subtlties of Gradient Descent: Scalability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_13_notes.html#stochastic-gradient-descent">15. Stochastic Gradient Descent</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#mini-batch-evaluation-of-the-gradient">Mini-batch Evaluation of the Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#mini-batch-evaluation-as-stochastic-gradients">Mini-batch Evaluation as Stochastic Gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#maximum-likelihood-with-stochastic-gradient-descent">Maximum Likelihood with Stochastic Gradient Descent</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_13_notes.html#non-convex-optimization">16. Non-Convex Optimization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#a-non-convex-optimization-example">A Non-Convex Optimization Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#gradient-descent-for-non-convex-optimization">Gradient Descent for Non-Convex Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#stochastic-optimization-for-non-convex-optimization">Stochastic Optimization for Non-Convex Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#another-non-convex-optimization-example">Another Non-Convex Optimization Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#id2">Stochastic Optimization for Non-Convex Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#the-idea-of-monte-carlo-optimization">The Idea of Monte Carlo Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#the-idea-of-simulated-annealing">The Idea of Simulated Annealing</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#design-choices-in-simulated-annealing">Design Choices in Simulated Annealing</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#the-simulated-annealing-algorithm">The Simulated Annealing Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_13_notes.html#simulated-annealing-for-non-convex-optimization">Simulated Annealing for Non-Convex Optimization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_14_notes.html">17. Lecture #14: Hamiltonian Monte Carlo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_14_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_14_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_14_notes.html#hierarchical-generalized-linear-models">18. Hierarchical Generalized Linear Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#generalized-linear-models">Generalized Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#kidney-cancer-dataset-pooling-vs-fully-independent-estimation">Kidney Cancer Dataset: Pooling vs Fully Independent Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#kidney-cancer-dataset-hierachical-vs-non-hiearchical-models">Kidney Cancer Dataset : Hierachical vs Non-Hiearchical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#a-hierarchical-generalized-linear-model-for-kidney-cancer">A Hierarchical Generalized Linear Model for Kidney Cancer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_14_notes.html#sampling-as-optimization">19. Sampling as Optimization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#when-is-metropolis-hastings-efficient">When is Metropolis Hastings Efficient?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#when-is-metropolis-hastings-inefficient">When is Metropolis Hastings Inefficient?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#the-connection-between-energy-and-density-functions">The Connection Between Energy and Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#the-connection-between-optimization-and-sampling">The Connection Between Optimization and Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#gradient-descent-with-random-momentum-simulating-mechanics-of-moving-particles">Gradient Descent with Random Momentum: Simulating Mechanics of Moving Particles</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#sampling-by-physical-simulation">Sampling by Physical Simulation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_14_notes.html#hamiltonian-monte-carlo">20. Hamiltonian Monte Carlo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#hamiltonian-motion-as-differential-equations">Hamiltonian Motion as Differential Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#hamiltonian-monte-carlo-with-exact-integration">Hamiltonian Monte Carlo: with Exact Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#correctness-of-hmc-with-exact-integration">Correctness of HMC with Exact Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#approximating-flows-sympletic-integrators">Approximating Flows: Sympletic Integrators</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#approximating-flows-adjusting-for-error">Approximating Flows: Adjusting for Error</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#hamiltonian-monte-carlo-with-the-leap-frog-integrator">Hamiltonian Monte Carlo: with the Leap Frog Integrator</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#hmc-with-leap-frog-integrator-in-action">HMC with Leap Frog Integrator in Action</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#hamiltonian-monte-carlo-summary">Hamiltonian Monte Carlo: Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#example-euclidean-gaussian-kinetic-energy">Example: Euclidean-Gaussian Kinetic Energy</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_14_notes.html#hmc-for-multimodal-distributions">HMC for Multimodal Distributions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_15_notes.html">21. Lecture #15: Parallel Tempering and Stochastic HMC</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_15_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_15_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_15_notes.html#review-of-hmc">22. Review of HMC</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#hamiltonian-monte-carlo-hmc">Hamiltonian Monte Carlo (HMC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#faqs-about-hmc">FAQs About HMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#hmc-for-multimodal-distributions">HMC for Multimodal Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#signs-of-maybe-convergence">Signs of Maybe Convergence?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#visual-diagnostics-traceplots-of-multiple-chains">Visual Diagnostics: Traceplots of Multiple Chains</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#autocorrelation-the-effective-sample-size">Autocorrelation: the “Effective” Sample Size</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#visual-diagnostics-the-autocorrelation-plot">Visual Diagnostics: The Autocorrelation Plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#quantitative-diagnostics">Quantitative Diagnostics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_15_notes.html#parallel-tempering">23. Parallel Tempering</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#multimodal-posteriors">Multimodal Posteriors</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#the-effect-of-temperature">The Effect of Temperature</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#the-idea-of-parallel-tempering">The Idea of Parallel Tempering</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#parallel-tempering-with-hmc">Parallel Tempering with HMC</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_15_notes.html#stochastic-gradient-hmc">24. Stochastic Gradient HMC</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#problems-with-scaling-hmc">Problems with Scaling HMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#naive-stochastic-gradient-hmc">Naïve Stochastic Gradient HMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#stochastic-gradient-hmc-with-friction">Stochastic Gradient HMC with Friction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_15_notes.html#stochastic-gradient-hmc-in-practice">Stochastic Gradient HMC in Practice</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_16_notes.html">25. Lecture #16: Neural Network Models for Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_16_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_16_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_16_notes.html#regression-as-generalized-linear-models">26. Regression as Generalized Linear Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#linear-regression-models">Linear Regression Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#how-would-you-parameterize-a-non-linear-trend">How Would You Parameterize a Non-linear Trend?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#review-of-the-geometry-of-logistic-regression">Review of the Geometry of Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#how-would-you-parametrize-a-ellipitical-decision-boundary">How would you parametrize a ellipitical decision boundary?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#how-would-you-parametrize-an-arbitrary-complex-decision-boundary">How would you parametrize an arbitrary complex decision boundary?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_16_notes.html#neural-networks">27. Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#approximating-arbitrarily-complex-decision-boundaries">Approximating Arbitrarily Complex Decision Boundaries</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#what-is-a-neural-network">What is a Neural Network?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#neural-networks-as-function-approximators">Neural Networks as Function Approximators</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#a-flexible-framework-for-function-approximation">A Flexible Framework for Function Approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#common-choices-for-the-activation-function">Common Choices for the Activation Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#neural-networks-are-universal-function-approximators">Neural Networks are Universal Function Approximators</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#neural-networks-regression">Neural Networks Regression</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_16_notes.html#automatic-differentiation-and-backpropagation">28. Automatic Differentiation and Backpropagation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#gradient-computation-for-neural-networks">Gradient Computation for Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#example-computing-neural-network-gradients">Example: Computing Neural Network Gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#backpropagation-gradient-descent-for-neural-networks">Backpropagation: Gradient Descent for Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#gradient-computation-with-automatic-differentiation">Gradient Computation with Automatic Differentiation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_16_notes.html#what-does-a-neural-network-learn">29. What Does a Neural Network Learn?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#why-is-a-neural-network-classifier-so-effective">Why is a Neural Network Classifier So Effective?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#id1">Why is a Neural Network Classifier So Effective?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#two-interpretations-of-a-neural-network-classifier">Two Interpretations of a Neural Network Classifier:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_16_notes.html#with-great-flexibility-comes-with-great-problems">30. With Great Flexibility Comes with Great Problems</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#neural-network-regression-vs-linear-regression">Neural Network Regression vs Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#interpretable-deep-learning">Interpretable Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#can-machine-learning-models-make-use-of-human-concepts">Can Machine Learning Models Make Use of Human Concepts?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#can-machine-learning-models-learn-to-explore-hypothetical-scenarios">Can Machine Learning Models Learn to Explore Hypothetical Scenarios?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#right-for-the-right-reasons">Right for the Right Reasons?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#the-perils-of-explanations">The Perils of Explanations</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#generalization-error-and-bias-variance">Generalization Error and Bias/Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_16_notes.html#generalization-of-deep-models">Generalization of Deep Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_17_notes.html">31. Lecture #17: Black-box Variational Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_17_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_17_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_17_notes.html#review-of-neural-network-models">32. Review of Neural Network Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#how-would-you-parameterize-a-non-linear-trend">How Would You Parameterize a Non-linear Trend?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#representing-arbitrarily-complex-functions">Representing Arbitrarily Complex Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#design-choices-depth-or-width">Design Choices: Depth or Width</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#neural-networks-regression">Neural Networks Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#the-maximum-likelihood-objective-is-non-convex-for-neural-networks">The Maximum Likelihood Objective is Non-Convex for Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#neural-network-regression-vs-linear-regression">Neural Network Regression vs Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#generalization-error-and-bias-variance">Generalization Error and Bias/Variance</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_17_notes.html#bayesian-neural-networks">33. Bayesian Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#bayesian-polynomial-regression-is-bayesian-linear-regression">Bayesian Polynomial Regression is Bayesian Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#id1">Bayesian Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_17_notes.html#black-box-variational-inference">34. Black-box Variational Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#review-of-variational-inference">Review of Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#variational-inference-as-optimization">Variational Inference as Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#variational-inference-for-bayesian-neural-networks">Variational Inference for Bayesian Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#rewriting-the-gradient-of-the-elbo">Rewriting the Gradient of the ELBO</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#id2">Black-Box Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#variance-of-the-gradient-estimate">Variance of the Gradient Estimate</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#gradient-of-the-elbo-with-the-reparametrization-trick">Gradient of the ELBO with the Reparametrization Trick</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#black-box-variational-inference-with-the-reparametrization-trick">Black-Box Variational Inference with the Reparametrization Trick</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#bbvi-for-bayesian-linear-regression-posterior-predictives">BBVI for Bayesian Linear Regression (Posterior Predictives)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_17_notes.html#bbvi-for-bayesian-linear-regression-posteriors">BBVI for Bayesian Linear Regression (Posteriors)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_18_notes.html">35. Lecture #18: Automatic Differentiation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_18_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_18_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_18_notes.html#review-of-black-box-variational-inference">36. Review of Black Box Variational Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#developments-in-computationally-efficient-variational-inference">Developments in Computationally Efficient Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#id1">Developments in Computationally Efficient Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#id2">Developments in Computationally Efficient Variational Inference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_18_notes.html#automatic-differentiation">37. Automatic Differentiation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#types-of-computational-differentiation">Types of Computational Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#numeric-differentiation">Numeric Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#symbolic-differentiation">Symbolic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#automatic-differentiation-the-idea">Automatic Differentiation: The Idea</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#evaluation-trace-and-computational-graph">Evaluation Trace and Computational Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#automatic-differentiation-forward-mode">Automatic Differentiation: Forward Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#automatic-differentiation-reverse-mode">Automatic Differentiation: Reverse Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#implementing-reverse-mode-autodiff">Implementing Reverse Mode AutoDiff</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_18_notes.html#an-example-of-reverse-mode-autodiff-in-python">An Example of Reverse Mode AutoDiff in <code class="docutils literal notranslate"><span class="pre">python</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_19_notes.html">38. Lecture #19: Variational Inference in Context</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_19_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_19_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_19_notes.html#how-to-evaluate-approximate-inference">39. How to Evaluate Approximate Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#how-good-is-your-variational-approximation-of-the-true-posterior">How Good is Your Variational Approximation of the True Posterior?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#alternative-posterior-evaluation-metrics">Alternative Posterior Evaluation Metrics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_19_notes.html#how-to-improve-approximate-inference">40. How to Improve Approximate Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#your-variational-approximation-sucks-can-you-fix-it">Your Variational Approximation Sucks, Can You Fix It?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#are-there-any-good-properties-of-variational-approximations-that-we-are-sure-about">Are There Any Good Properties of Variational Approximations that We Are Sure About?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#why-is-inference-for-neural-networks-hard">Why is Inference for Neural Networks Hard?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#it-s-weirder-than-you-can-imagine">It’s Weirder Than You Can Imagine</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_19_notes.html#but-why-do-i-care">41. But why do I care?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#evaluation-of-variational-approximation-for-real-down-stream-tasks">Evaluation of Variational Approximation for Real Down-stream Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#predictiveness-of-the-variational-approximate-posterior">Predictiveness of the Variational Approximate Posterior</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#quality-of-variational-approximate-posterior-predictive-uncertainty">Quality of Variational Approximate Posterior Predictive Uncertainty</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#does-a-poor-posterior-approximation-imply-a-poor-posterior-predictive">Does a Poor Posterior Approximation Imply a Poor Posterior Predictive?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_19_notes.html#new-developments-in-deep-bayes">42. New Developments in Deep Bayes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#what-s-wrong-with-posterior-approximations-for-bnns">What’s Wrong with Posterior Approximations for BNNs</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#what-did-we-learn">What Did We Learn?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#what-s-wrong-with-the-predictions-from-mean-field-variational-posteriors-of-bnns">What’s Wrong with the Predictions from Mean-Field Variational Posteriors of BNNs?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#relationships-between-deep-ensembles-and-bayesian-neural-networks">Relationships Between Deep Ensembles and Bayesian Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#alternative-models-for-uncertainty-quantification">Alternative Models for Uncertainty Quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#predictive-uncertainties-of-alternative-deep-bayesian-models-may-not-be-better">Predictive Uncertainties of Alternative Deep Bayesian Models May Not be Better</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_19_notes.html#what-uncertainties-do-we-need-in-deep-learning">What Uncertainties Do We Need in Deep Learning?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_20_notes.html">43. Lecture #20: Variational Autoencoders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_20_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_20_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_20_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_20_notes.html#outline">Outline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_20_notes.html#applications-of-generative-models">44. Applications of generative models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_20_notes.html#review-of-latent-variable-models">Review of Latent Variable Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_20_notes.html#factor-analysis-models">Factor Analysis Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_20_notes.html#applications">Applications</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_20_notes.html#motivation-for-generative-models">Motivation for Generative Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_20_notes.html#motivation-for-deep-generative-models">Motivation for Deep Generative Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_20_notes.html#generating-data-with-variational-autoencoders">Generating Data with Variational Autoencoders</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_20_notes.html#inference-for-deep-generative-models-vaes">45. Inference for deep generative models: VAEs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_20_notes.html#expectation-maximization-estimating-the-mle-for-latent-variable-models">Expectation Maximization: Estimating the MLE for Latent Variable Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures/lecture_21_notes.html">46. Lecture #21: Implementation of Variational Autoencoders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_21_notes.html#am-207-advanced-scientific-computing">AM 207: Advanced Scientific Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_21_notes.html#stochastic-methods-for-data-analysis-inference-and-optimization">Stochastic Methods for Data Analysis, Inference and Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lectures/lecture_21_notes.html#fall-2021">Fall, 2021</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_21_notes.html#outline">Outline</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_21_notes.html#overall-structure-of-vae-implementation">Overall Structure of VAE Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_21_notes.html#defining-make-objective">Defining <code class="docutils literal notranslate"><span class="pre">.make_objective</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures/lecture_21_notes.html#defining-log-likelihood">Defining <code class="docutils literal notranslate"><span class="pre">.log_likelihood</span></code></a></li>
</ul>
</li>
</ul>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="right-next"
       href="lectures/lecture_1_notes.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1. </span>Lecture #1: Course Overview</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#syllabus">Syllabus</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#schedule">Schedule</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-notes">Lecture Notes</a><ul class="nav section-nav flex-column">
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yaniv Yacoby
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>